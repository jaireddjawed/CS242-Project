[
    {
        "title": "What test to use.",
        "author": "angelicwoodchuck",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ft3t8/what_test_to_use/",
        "text": "So I have a study for a final project and stats is not my strongpoint. It’s not even for a statistics class, it’s an operations management class so I don’t know why they have us doing stats projects, but I digress.\nThe study that my group decided to do was for weight lifting. We have like a sample size of 10 people, and we have them hold out a 10 lb weight and time it. We tell them to just hold it until holding it is too uncomfortable to  hold any longer. We then had them do it again 8 hours later. What type of test would be the best to show statistical significance of whether or not the First test was better than the 2nd?",
        "created_utc": 1525025532,
        "upvote_ratio": ""
    },
    {
        "title": "Is classical (non-Bayesian) statistics relevant to machine learning and data analysis?",
        "author": "ANewPope23",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ft09v/is_classical_nonbayesian_statistics_relevant_to/",
        "text": "I am a beginning student of statistics and data analysis. I am wondering if classical (non-Bayesian) statistics is useful for machine learning/data analysis? I get the impression that only Bayesian stuff is useful and that classical statistics is useful only for analysing scientific/medical experiments.\n\nIf I want to do data analysis/machine learning, should I just skip to Bayesian statistics?",
        "created_utc": 1525024687,
        "upvote_ratio": ""
    },
    {
        "title": "Econometrics project help",
        "author": "Shisha95",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fscvl/econometrics_project_help/",
        "text": "\n\nI am supposed to run a multiple regression with GDP as my dependent variable and  consumer confidence, producer confidence and share price index.as my independent variables over 31 quarters. I took the growth of all mentioned variables and constructed my model.  \n\nHowever, In the middle of my assignment i am asked this question \" Conduct a test of whether a drop of 1% of consumer confidence has the same effect on GDP growth as a 1% drop in producer confidence. State clearly your null and alternative hypotheses\". I cant understand what do now and I cant' move forward anymore in my assignment.\n\nThanks in advance. \n\n\n\n",
        "created_utc": 1525018939,
        "upvote_ratio": ""
    },
    {
        "title": "Is the correlation coefficient a synonym for Coefficient of Variation(CV)",
        "author": "armantopchu",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fs7uc/is_the_correlation_coefficient_a_synonym_for/",
        "text": "R squared is the coefficient of determination and shows the strength of the relationship. \n\nThe coefficient of variation(CV aka r) is the Standard deviation transformed into a percentage. It’s a dimensionless number that can be used for comparing data sets of different sizes etc. \n\nWhenever in exams they mention the “correlation coefficient” are they talking about CV? ",
        "created_utc": 1525017651,
        "upvote_ratio": ""
    },
    {
        "title": "Please help",
        "author": "Shisha95",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8frwyg/please_help/",
        "text": "How can I test in a multiple regression model wether a drop of 1% x1 will cause a larger effect than a 1% drop in x2, given that I used the gtowth rates of my dependent(GDP) and independent variables(stock indexes &amp; consumer index)? Pleasee helpp",
        "created_utc": 1525014726,
        "upvote_ratio": ""
    },
    {
        "title": "Pleasee helppp",
        "author": "Shisha95",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8frlgq/pleasee_helppp/",
        "text": "How can I test in multiple regression model wether a drop of 1% x1 will cause a larger effect than a 1% drop in x2, given that I tool the gtowth rates of my dependent and independent variables? ",
        "created_utc": 1525011513,
        "upvote_ratio": ""
    },
    {
        "title": "How do I use regression to predict a future outcome?",
        "author": "apagandolasluces",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8frii8/how_do_i_use_regression_to_predict_a_future/",
        "text": "It's an assignment for my Data Analytics class, we're using SPSS and trying to predict how long a patient will spend in an emergency room, using a set of independent variables like age, triage, whether or not they get admitted to hospital, and their gender. \n\nAny help would be greatly appreciated.",
        "created_utc": 1525010684,
        "upvote_ratio": ""
    },
    {
        "title": "Regression towards the mean in data with a long right tail",
        "author": "maxhallinan",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fr6vx/regression_towards_the_mean_in_data_with_a_long/",
        "text": "I have a dataset scraped from a link sharing site. Users on this site submit links and readers vote on links they like. I've [plotted](https://screenshots.firefox.com/2WZ9lvkvLVjiim4X/null) each user's average score (y axis) and their submission count (x axis). And I've added an additional horizontal line through the plot indicating the overall average submission score (8.91 points). The majority of users have submitted less than 100 links. But there are several outliers. The user who has submitted the most links has submitted some 4k links which is roughly twice as many as the user with the next highest number of submissions. The upvote average of the user with ~4k submissions is almost exactly the overall upvote average. And generally the plot shows that users with more submissions fall closer to the average line. Is this regression towards the mean or is the mean dominated by the most prolific user? I have no formal statistics education and I am unsure how to think about this data. ",
        "created_utc": 1525006779,
        "upvote_ratio": ""
    },
    {
        "title": "Fastest way to eliminate players in a two option multiple choice quiz game (people sit down after a wrong answer)",
        "author": "shanef1978",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fqtmq/fastest_way_to_eliminate_players_in_a_two_option/",
        "text": "Here's a situation I'm in, that I'm trying to think of a statistical approach for. \n\nI help to run a pub quiz.  The questions are written by a company who does this for pubs and other venues all over New Zealand.  One part of the quiz involves a game that eliminates participants progressively until one person is left.  What I'm wondering is how I can eliminate people the fastest. This is how it works:\n\n1.  All participants stand up. \n2.  A multiple choice general knowledge question is read out, that has two possible answers. \n3.  If a participant think it's the first option given, they put their hands on their head.  If they think it's the second option given, they put their hands on their backside. \n4.  The answer is revealed.  People who are wrong sit down. \n5.  Play continues with people still standing, until one person is left standing, or until 10 questions have been read out (that is all that is supplied). \n\nWhat I've tried doing so far is categorising the questions as either easy or hard, and asking the hard ones first, and giving easier questions as the game progresses.  That eliminates a lot of people at the start, but the ones left after a few questions tend to remain. \n\nI've also tried spreading harder questions throughout, rather than have them at the start. It's early days but I don't think that helps much either. \n\nI haven't kept any data, but it probably takes about 8 questions on average to get down to one lone player. \n\nAny thoughts on what data I should collect or how I should go about this? \n\n",
        "created_utc": 1525001780,
        "upvote_ratio": ""
    },
    {
        "title": "What test should I use for measuring association between a continuous variable, and a categorical variable?",
        "author": "nh_2323",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fqot8/what_test_should_i_use_for_measuring_association/",
        "text": "I seem to be having a bit of brain fart and just can't seem work out what test I need to use. I'm measuring association between a persons weight (continuous) and the weight category of their father (normal, overweight, obese). Would someone be nice enough to help out my foggy brain?",
        "created_utc": 1524999717,
        "upvote_ratio": ""
    },
    {
        "title": "What does 'probability proportional to xi' mean?",
        "author": "[deleted]",
        "url": "https://i.redd.it/5i49sbmigtu01.png",
        "text": "[deleted]",
        "created_utc": 1524994631,
        "upvote_ratio": ""
    },
    {
        "title": "How to solve this Pearon Correlation Coefficient question?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fq9je/how_to_solve_this_pearon_correlation_coefficient/",
        "text": "[deleted]",
        "created_utc": 1524992573,
        "upvote_ratio": ""
    },
    {
        "title": "Confounding v Effect Modification",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fpqpb/confounding_v_effect_modification/",
        "text": "[deleted]",
        "created_utc": 1524983870,
        "upvote_ratio": ""
    },
    {
        "title": "Proof that white noise + white noise = double-power white noise?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fosrd/proof_that_white_noise_white_noise_doublepower/",
        "text": "[deleted]",
        "created_utc": 1524971385,
        "upvote_ratio": ""
    },
    {
        "title": "Should I use the same predictors for two regression models?",
        "author": "hashtagNerdBash2018",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8foms0/should_i_use_the_same_predictors_for_two/",
        "text": "I'm modeling student's test scores for Math and Reading. I was wondering if I should try to keep the predictors similar for the two models so that it is easier for my client?\nMy models are the following:\n\n- Math Score ~ (Last Year Math Score)\n\n- Reading Score ~ (Last Year Reading Score) + Indicator\n\nThe Indicator is not significant for the Math model. It is significant in the Reading model but the coefficient is small and the R^2 is basically the same as when I remove it. Should I bother including this indicator variable in the Reading model?",
        "created_utc": 1524969441,
        "upvote_ratio": ""
    },
    {
        "title": "Solutions to Forecasting &amp; Time Series Analysis (2nd edition) by Montgomery et al.",
        "author": "MasonBo_90",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fomjj/solutions_to_forecasting_time_series_analysis_2nd/",
        "text": "Does anyone know where I can a solutions guide to the 2nd edition of **Forecasting &amp; Time Series Analysis** by Montgomery, Johnson, and Gardiner?\n\nThanks a lot!",
        "created_utc": 1524969364,
        "upvote_ratio": ""
    },
    {
        "title": "Heights and Widths of U.S. States",
        "author": "BowserJrDood",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8foizq/heights_and_widths_of_us_states/",
        "text": "Hello, I hope I'm posting in the right subreddit, I looked in some places and this seemed correct. I've been doing something and I wanted to find a list of the U.S. States by height and width. And by that I mean the distance in miles from the most northern point in the state's latitude to the most southern point's latitude would be the states height and the most the western point in the state's longitude to the most eastern point's longitude would be the width (Though Alaska would have to be figured differently). I've looked and I've came up with mostly nothing, I found one place but the accuracy seemed shaky. I'd try and figure it out myself, but I don't fully understand figuring out problems with longitude and latitude like this and I want it to be very accurate. If you know a place that can help me with this better anything is appreciated!",
        "created_utc": 1524968195,
        "upvote_ratio": ""
    },
    {
        "title": "How to make box &amp; whisker plots, but spaced at specific x-axis locations?",
        "author": "Atomicbob11",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fngq1/how_to_make_box_whisker_plots_but_spaced_at/",
        "text": "Hi, I have box-and-whisker plot data that I've made, specifically in Graphpad Prism 6. However, this data is also as a function of distance. I would like to represent distance on the x-axis, so each box-and-whisker plot would sit at different locations (not equal intervals) along the x-axis.\n\nAny opinions on the best way to do this? A simple example would be a plot at 1, 3, 5, 6.5, and 7 (if values were 1-7 on the x-axis). I've been using Graphpad Prism 6, but would be willing to use another application with whatever will allow this to happen the easiest.\n\nThanks!",
        "created_utc": 1524956659,
        "upvote_ratio": ""
    },
    {
        "title": "Statistic question",
        "author": "randomperson2453",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fmkge/statistic_question/",
        "text": "Q: https://imgur.com/a/P7ZU4sN\n\nHi, I am a bit stuck with this question. I can't figure out what topic this question is on, so I don't really know what approach to use... Any hints?\n\nThanks in advance",
        "created_utc": 1524947772,
        "upvote_ratio": ""
    },
    {
        "title": "How to do out of sample forecast in R?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fm8rw/how_to_do_out_of_sample_forecast_in_r/",
        "text": "[deleted]",
        "created_utc": 1524944683,
        "upvote_ratio": ""
    },
    {
        "title": "Relationship Between R and R^2 Question",
        "author": "BLTspirit",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8flpgn/relationship_between_r_and_r2_question/",
        "text": "Ok so I am a complete noob at this stuff. I am making a program that takes data and makes regressions for it. I was wondering. Can I get the coefficient of determination (R squared) by simply squaring the coefficient of correlation (R)? This does not seem to make sense to me because R is found using only the x and y pairs from the data while R squared is supposed to relate the data to a regression... What am I missing here?",
        "created_utc": 1524939730,
        "upvote_ratio": ""
    },
    {
        "title": "how do you model risk of something that does not have historic data?",
        "author": "maximus12793",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fla5q/how_do_you_model_risk_of_something_that_does_not/",
        "text": "**I am trying to simulate a backtest on an options strategy. But my question is this:**\n\n\nSince there is not way to get 'historical' premiums similar to how equities have daily closing prices what would be a realistic way to model this data? To clarify, I am trying to backtest the probability that an option placed consistently __% away from the current stock price is sound.\n\n&gt; Ex: Say I had a naive strategy that was simply to sell put options that were 5% below the current share price of $SPY w/ 1 week expiry. Would I then record *N* months worth of data on options falling in this percentage and stipulate that this would hold for the future and then use historical data of underlying to predict the profit/loss? (Meaning the cost to close the option at the end of 1 week).\n\n\nI feel like this would be pretty poor since I am missing years of prior data, but I am not sure if there is a better way to approach this. \n\n-----------------------------------------------------------\n\nI was also thinking I could just use historical data of the stock and then calculate the option premium price (at or below this __%, because it is a sold put). CBOE has a calculator to do this pricing without prior data i.e. https://imgur.com/a/wuqLqeN. Then, use this value to calculate hypothetical p/l (with historical data giving IV etc.)? Any alternative ideas/tips would be greatly appreciated! ",
        "created_utc": 1524935805,
        "upvote_ratio": ""
    },
    {
        "title": "How do I find the relationship between two rating scores",
        "author": "Next-User",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fl9cr/how_do_i_find_the_relationship_between_two_rating/",
        "text": "Hi,\nI am trying to find the relationship between two pairs of ratings from 1-10. I am used to just using scale data for this, and I assume that a rating score from 1-10 is considered ordinal?\n\nWhat do I need to use to run this in SPSS. Would it be Spearman's or can I use Pearson's?\n\nPlease help and thanks in advance!",
        "created_utc": 1524935606,
        "upvote_ratio": ""
    },
    {
        "title": "How do I find the OLS for this equation",
        "author": "maskedself",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fkfbe/how_do_i_find_the_ols_for_this_equation/",
        "text": "ei=y*i*-b1x*i*+b2x*i*^2\n\nWhenever I try to find b1 and b2 that minimize the error through elimination I end up cancelling both b1 and b2 help\n\nIf what I wrote is confusing I can try and upload my working out, thank you \n\nSorry for any confusions...i'm a bit lost in this statistics course i'm doing and my professor doesn't fully explain everything, this feels like a calculus course more than anything. \n\nedit: made formatting easier",
        "created_utc": 1524927803,
        "upvote_ratio": ""
    },
    {
        "title": "Sampling weights use in STATA",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fk4wg/sampling_weights_use_in_stata/",
        "text": "[deleted]",
        "created_utc": 1524924932,
        "upvote_ratio": ""
    },
    {
        "title": "How do I enter multiple nominal data into one variabel in SPSS?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fjgb4/how_do_i_enter_multiple_nominal_data_into_one/",
        "text": "[deleted]",
        "created_utc": 1524916847,
        "upvote_ratio": ""
    },
    {
        "title": "How can you adjust a chi-square test if n/N&gt;.1 (if the “independent condition” is not met)?",
        "author": "FromBreadBeardForm",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fgcmd/how_can_you_adjust_a_chisquare_test_if_nn1_if_the/",
        "text": "For proportions and means we can adjust our calculation of standard deviation if sample size is more than 10% of population size. Is there any similar adjustment for chi-square test?",
        "created_utc": 1524875710,
        "upvote_ratio": ""
    },
    {
        "title": "Test Method Variability",
        "author": "SANPres09",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fer4l/test_method_variability/",
        "text": "Hey folks, first time questioner here with something I've wondered how to calculate.\n\nI use a test method at work and I want to understand the variability of it. I know there is variability in every samples and every test, what I want to know is the variability of the test itself. When I report a value of 5, what is the inherent plus or minus attached to that because I used this specific test. I have evaluated linear models but they don't seem to make sense; I am not plotting independent and dependent variables, I just want to know how much each sample varies from its own mean, compiled into one coherent value for the test itself.\n\nThe dataset I have consists of about 1000 data points with every sample tested in triplicate.\n\nThanks for providing some advice!",
        "created_utc": 1524860716,
        "upvote_ratio": ""
    },
    {
        "title": "Question regarding standard deviation in frequency distribution",
        "author": "Wizbillz",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fe4r2/question_regarding_standard_deviation_in/",
        "text": "|Salary \\($00\\)|Number of Employees\\(X\\)|Mid Point\\(f\\)|X x F|X\\-mean\\(45.85\\)|\\(X\\-mean\\)2| \\(X\\-mean\\)2 x f|\n|:-|:-|:-|:-|:-|:-|:-|\n|25 and under 35|24|30|720|\\-21.85|477.42|11458.08|\n|35 and under 45|41|40|1640|\\-4.85|23.52|964.32|\n|45 and under 55|44|50|2200|\\-1.85|3.42|150.48|\n|55 and under 65|19|60|1140|\\-26.85|720.92|13697.48|\n|65 and under 75|7|70|490|\\-38.85|1509.32|10565.24|\n||sum=135||sum=6190|||=sum 36835.6|\n||||6190/135=45.85|||36835.6/135=272.86|\n\n# Hey Guys,\n\nCan anyone help me find the standard deviation here? I have the answer but I cannot figure out how to get it. My textbook tells me to take the square root of 272.86 which is 16.52 but my math exam has it as 10.95. I am 100&amp;#37; sure that the mean is 45.85\n\n\nThank you and have a great day! ",
        "created_utc": 1524855582,
        "upvote_ratio": ""
    },
    {
        "title": "How do i calculate the linear equation from my binary logistic regression coefficients from SPSS?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fdr11/how_do_i_calculate_the_linear_equation_from_my/",
        "text": "[deleted]",
        "created_utc": 1524852516,
        "upvote_ratio": ""
    },
    {
        "title": "is there rule of thumb for # of datapoints to run a regression?",
        "author": "ktoshzz",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fd0vu/is_there_rule_of_thumb_for_of_datapoints_to_run_a/",
        "text": "Another basic question from a stats beginner.\n\nIif i am going to run a regression, is there a rule of thumb for the minimum number of datapoints (say for a simple regression with 2 continuous variables)?\n\nsomeone told me you would want 30 rows of data (60 datapoints / 2 variables) at a minimum...\n\nAny insight on how to think of this issue would be greatly appreciated.\n\nThanks.  ",
        "created_utc": 1524846838,
        "upvote_ratio": ""
    },
    {
        "title": "regression question",
        "author": "ktoshzz",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fc9fe/regression_question/",
        "text": "Do the results of a multivariate regression tell you which independent variables have the most predictive power?\n\nFor example, if I run a regression with the following: dependent variable is Vo2 Max; independent variables are age, weight, heart rate, gender. \n\nBased on the output of the regression can I tell which independent variable (age, weight, heart rate, gender) is the most predictive? Can I just look at the independent variable with the highest confidence interval?\n\nOr would I run a bivariate regression for each of the independent variables and compare the R2s?\n\nThank you.",
        "created_utc": 1524840937,
        "upvote_ratio": ""
    },
    {
        "title": "What method would you use to find correlation between two questions using likert scala?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fandi/what_method_would_you_use_to_find_correlation/",
        "text": "[deleted]",
        "created_utc": 1524825361,
        "upvote_ratio": ""
    },
    {
        "title": "sequential/interim analysis, sources on how to use with different kinds of statistical tests?",
        "author": "Forthethirdtime",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8falb0/sequentialinterim_analysis_sources_on_how_to_use/",
        "text": "Hi,\n\nI'm looking to calculate p-value boundaries for a 2 time sequential analysis. All sources that I've read report how to calculate Z-boundaries and associated p-value boundaries. How does this work for other distributions, say for the F-distribution when you want to do an ANOVA? Can you then calculate F-boundaries? \n\nThanks in advance",
        "created_utc": 1524824636,
        "upvote_ratio": ""
    },
    {
        "title": "What are some reasons to not choose a valid experimental design?",
        "author": "savemeimdying",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8fa9v9/what_are_some_reasons_to_not_choose_a_valid/",
        "text": "I am studying for an exam and one of the questions from a previous exam is about using fertiliser on trees. In it 8 trees were chosen as controls and 6 got the fertiliser \"treatment\". The question asks for reason why a balanced design wasn't used and I cannot think of any.\n\nTo me all it would take is to give one of the control trees fertiliser. Hardly expensive or time consuming which would be my go to answers otherwise.",
        "created_utc": 1524820427,
        "upvote_ratio": ""
    },
    {
        "title": "Are these A/B test results statistically significant or should I get more data?",
        "author": "minomes",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f93e1/are_these_ab_test_results_statistically/",
        "text": "I'm new to split-testing and statistics in general. \n\nWould be really grateful for a few opinions on whether it's safe to pick a winner from the follow test results:\n\nI own a website. I \"split\" 4,000 visitors evenly, so 33.3% would see one of three different page variations. Let's just call it Variation A, B and C.\n\nResults:\n\nVariation A got 13 sales\n\nVariation B got 12 sales\n\nVariation C got 17 sales\n\nSo obviously I'm tempted to say, \"Variation C is clearly the best\". But I'm just wondering from a statistics perspective, how sound this reasoning is.\n\nAnd if not, what would you want to see to feel confident in this result? 8,000 views? 10,000? (as opposed to the 4,000 I got).\n\nThanks for any help/insights I get. ",
        "created_utc": 1524804692,
        "upvote_ratio": ""
    },
    {
        "title": "How can stratification be used to estimate the correlation between two groups?",
        "author": "Fatcatinthetophat",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f7u8e/how_can_stratification_be_used_to_estimate_the/",
        "text": "I'm working with data from a pre and post test, but the tests aren't matched. I can stratify the data across certain demographics, and have heard that stratification can be used to estimate the correlation between correlated groups, but I don't understand how. Could someone explain it to me, or point me to an easily understandable explanation?",
        "created_utc": 1524791599,
        "upvote_ratio": ""
    },
    {
        "title": "How is Mean squared error among the groups is an estimate of the population variance in one way ANOVA",
        "author": "AnyRandUserName",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f4eyy/how_is_mean_squared_error_among_the_groups_is_an/",
        "text": "Hello,\n\nUnder the null hypothesis in one way ANOVA, we say that Mean squared error between the groups which is sum of squared error between groups divided by number of groups minus 1, is an estimator of population variance sigma?\n\nI get that under the null hypothesis, sample means of groups are to be thought of as samples taken from a normal random variable with mean equal to population mean and variance equal to population variance divided by number of groups because the group populations are assumed to be normal\n\nBut I'm mathematically unable to derive that because of factor of group size multiplied in the sum of squared error.\n\nAny help would be appreciated\n\nThanks",
        "created_utc": 1524763265,
        "upvote_ratio": ""
    },
    {
        "title": "What's the best way to qualitatively measure how similar two datasets to each other?",
        "author": "mikerowave",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f2s6v/whats_the_best_way_to_qualitatively_measure_how/",
        "text": "I need to compute some sort of statistic that describes quantifies the similarity fo two datasets. I would like the statistic to be normalized in such a way such the the value is universally comparable and the degree of \"sameness\" is simple to understand (1 = datasets are very very similar or the same, and a near-0 value = datasets are very different)\n\nAnyone have any ideas?",
        "created_utc": 1524750604,
        "upvote_ratio": ""
    },
    {
        "title": "Standard deviation of forecasting errors in a moving average process",
        "author": "MasonBo_90",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f2lp2/standard_deviation_of_forecasting_errors_in_a/",
        "text": "If I have a moving average process of order 6, MA(6), as the estimator of a constant model and I use it to forecast 12 steps ahead. \n\na) How much the standard deviation of the forecast errors will decrease if I use a MA(12) instead?\n\nb) What value should N (the denominator of the MA process) assume to decrease the standard deviation of the forecast errors by 25% and by 50%?\n",
        "created_utc": 1524748987,
        "upvote_ratio": ""
    },
    {
        "title": "Trying to understand when/how to use Bland-Altman Plots",
        "author": "staccus-legano",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f2ggs/trying_to_understand_whenhow_to_use_blandaltman/",
        "text": "As far as I understand Bland-Altman plots are used to compare two different methods of measurement. But I have trouble to understand how the plot is interpreted.  \n\nIs it correct to assume that the closer the data points scatter around the line of the mean difference the smaller is the difference between both methods?\nWhat do the limits of agreement indicate and what does it mean if data points are outside of these limits?\nI've also seen 95% CI around the limits of agreement. What do these indicate?\nThank you in advance.",
        "created_utc": 1524747730,
        "upvote_ratio": ""
    },
    {
        "title": "I am making a prediction based on a quantitative input, which implies to me that I should use regression, however, I would like a probabilistic range of values as the output instead of a single value. What options are available to me?",
        "author": "GetFlyOnMyOwnSupply",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f0q7k/i_am_making_a_prediction_based_on_a_quantitative/",
        "text": "",
        "created_utc": 1524726228,
        "upvote_ratio": ""
    },
    {
        "title": "I have the probability that X is less than x, given that Y is less than y, and the probability that X is less than x, given that Y is greater than y. Can I make any inferences about the probability that X is less than x, given that Y is exactly equal to y?",
        "author": "GetFlyOnMyOwnSupply",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f0lr7/i_have_the_probability_that_x_is_less_than_x/",
        "text": "For a practical example: \n\n\nThe probability that a runningback at the NFL scouting combine will run the 40 yard dash in less than 4.5 seconds, given that the runningback weighs less than 220 lbs, is .36. The probability that a runningback will a better than 4.5 40, given that he weighs more than 220 lbs, is .19. From this data, can I approximate \\(or calculate\\) the probability that a runningback will run a 40 yard dash in less than 4.5 seconds, given that he weighs \\*exactly\\* 220 lbs?",
        "created_utc": 1524724575,
        "upvote_ratio": ""
    },
    {
        "title": "How to interpret difference in correlation coefficient between 'absolute value' correl and 'returns' correl?",
        "author": "npjobs",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f0iku/how_to_interpret_difference_in_correlation/",
        "text": "Hi all,\n\nBeen really bewildered by this situation - I'm running a correlation between 'A' and 'B'; and 'C' and 'D'. I've encountered 2 scenarios which I can't really explain:\n\n1) High correlation between absolute values of 'A' and 'B' but low correlation between 'change in A' and 'change in B'. 'Change in A' refers % difference. So in Period 1 if A=100 and in Period 2, A=110, 'change in 'A' would be 10%.\n\n2) Negative correlation between absolute values of 'C' and 'D', but relatively strong positive correlation between 'change in C' and 'change in D'. \n\nAFAIK - Scenario (1) implies that the deviations from the mean absolute value move in the same direction, but deviations from the mean changes don't move together as well. **But what does this truly mean?** How can I interpret this in a lay-man's sense?\n\nNo real idea about scenario (2)...",
        "created_utc": 1524723403,
        "upvote_ratio": ""
    },
    {
        "title": "A question about combinatorics",
        "author": "itbobn",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f0cwm/a_question_about_combinatorics/",
        "text": "My question(and part of the given solution) is in the image.\n\nhttps://imgur.com/a/oPgEdN1 Its more of an entropy problem but the issue I'm having\n\nwith is how do they come up mathematically with there being 8 possibilities of there being 5 games, 20 possibilities for 6 games, etc.\n\nThanks\n",
        "created_utc": 1524721376,
        "upvote_ratio": ""
    },
    {
        "title": "Blocking in Statistics",
        "author": "Ho_Kogan",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f08pm/blocking_in_statistics/",
        "text": "Reading up on this concept and there are a few key points I don't get:\n\nIs blocking a reactive or proactive concept ?  Like is it a consequence of me testing a hypothesis out and then doing the math/run a program to compensate for variability between 2 or more factors. Or do I choose which uncontrollable factor(s) can be considered and add it as a factor in the test, then confound it to a \"statistical block\".\n\nI hope this makes sense,\n\nthanks !\n\nEdit:  Thanks, I found my solution by asking around:  Turns out a program like Minitab automatically considers blocks into its calculations.  First figure out how many factors and blocks you want.  Generate a design.  Analyze the design.  Done",
        "created_utc": 1524719928,
        "upvote_ratio": ""
    },
    {
        "title": "Need help with figuring out how to regress this data. What approach should I take?",
        "author": "Powerful_Tune",
        "url": "https://i.redd.it/yg63aydcn6u01.png",
        "text": "",
        "created_utc": 1524717850,
        "upvote_ratio": ""
    },
    {
        "title": "[Stats 2nd Year] Dependent vs. Independent variables ; Please help, real quick",
        "author": "RelatedArtist03",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8f00jx/stats_2nd_year_dependent_vs_independent_variables/",
        "text": "Hello, I was wondering if someone could explain to me which variables are dependent in the 2009 document. I already know what variables are dependent in the 2014 document because they say variable A based on variable B + variable C. They dont say this in the 2009 document. An example of a dependent variable in the 2014 document is SPSDINT. Again I am looking for a way to tell which variables are independent vs dependent in the 2009 document.\n\n2009: https://drive.google.com/file/d/1gQZMgYpyP7MzK5HuZgYgrhEWzM76pRuE/view?usp=sharing\n\n2014: https://drive.google.com/open?id=1F0fFPaNI8YU-T33aamSoyyMQGXLQPLiX",
        "created_utc": 1524717220,
        "upvote_ratio": ""
    },
    {
        "title": "which stat model should i use to meassure how much each IV affects the choice of the DV? ols?",
        "author": "Eddiehondo",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ezp30/which_stat_model_should_i_use_to_meassure_how/",
        "text": "Hello everyone, i hope someone is willing to help me, im working on my college thesis, in which im trying to know how 3 attributes of ice cream affects the choice of buying an ice cream.\nso, the independent variables are the attributes and the dependent variable is the decision to buy them. i was thinking of using an OLS model but im not really sure if it really works in this case.\nim using a poll to meassure the attributes using an ordinal scale (strongly agree, agree, neutral, disagree and strongly disagree)\nI.E \"when im buying an ice cream the most important thing is the flavor\" strongly agree, agree, neutral, disagree and strongly disagree.\nif anyone is reading this, Thank You.\nbye",
        "created_utc": 1524713745,
        "upvote_ratio": ""
    },
    {
        "title": "How can you predict a binary outcome with only categorical variables?",
        "author": "Statquestions12",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eyb3v/how_can_you_predict_a_binary_outcome_with_only/",
        "text": "Can you use regression for this? I know you can use logistical regression if your independent variables are a mix of quantitative and qualitative, but I'm not sure if you can if it's all qualitative.\n\nThe binary outcome would be something like Satisfied and Dissatisfied, and each row would only contain one or the other.",
        "created_utc": 1524700479,
        "upvote_ratio": ""
    },
    {
        "title": "Understand and interpret correlation",
        "author": "juliegris",
        "url": "https://i.redd.it/5elaocz1d4u01.jpg",
        "text": "",
        "created_utc": 1524690207,
        "upvote_ratio": ""
    },
    {
        "title": "would you report the confidence interval immediately after reporting t-test?",
        "author": "emmaserena21",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8evyuw/would_you_report_the_confidence_interval/",
        "text": "For example, t(134)=-2.60,p&lt;.05, 95% CI [-21.137,-2.887]",
        "created_utc": 1524681612,
        "upvote_ratio": ""
    },
    {
        "title": "Binary logistic regression getting the minimal predictive values for a positive outcome",
        "author": "Orumas",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ev71z/binary_logistic_regression_getting_the_minimal/",
        "text": "Hello everyone,\nJust make clear, i got not much of statistical education and trying hard to find out which way to go is the right one. In short: I'm doing research and we are trying to find predictive values for patients to go to surgery instead of participating in possibly useless treatment. So my results of logistic regression, when the independent value was 1=surgery 0=no surgery, that we had 4 values which had p&lt;0.05. Here is where i'm stuck: how do i find out minimal values that \"could predict\" that a patient should go surgery under certain numbers of these 4 values? Is this even possible? I found the logit(p)=B0+B1*x1... and so on, is this what im looking for?\nThanks for any kind of help.",
        "created_utc": 1524675855,
        "upvote_ratio": ""
    },
    {
        "title": "ARIMA stationary time series",
        "author": "MLbeginner96",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eulmw/arima_stationary_time_series/",
        "text": "Does a time series need to be stationary before fitting an ARIMA model to it and generating forecasts? I know ARMA does but is it the  same for ARIMA? Getting mixed messages all over the net",
        "created_utc": 1524671401,
        "upvote_ratio": ""
    },
    {
        "title": "Confirmation Chi-squared",
        "author": "staticseven",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8etskx/confirmation_chisquared/",
        "text": "Hi all,\nI am NOT a stats guy at all but I'm attempting to engage with it as best I can. I've followed the suggested links but need some follow up advice before I continue.\n\nHave a dataset that consists of many log entries. Each log has a couple of categories/attributes attached to it (between 1 and 5) coded as binary 1s and 0s for present and not present. There are 50 possible attributes across the dataset. There are approx 700 logs. The study is longitudinal (although I don't think thats relevant for this test).\nI want to see which attributes are significantly associated i.e. which most likely occur in conjunction with other attributes. And also which are least likely to occur together.\nThe data is qualitative/categorical in nature. There is no scale/hierarchy etc.\n\nI \"think\" I should be using Chi-squared to test this. Can someone confirm? I originally thought Spearman's Rho but that's for ordinal data yes?\n\nThanks (also sorry if this is inappropriate, not meant to irritate).",
        "created_utc": 1524665066,
        "upvote_ratio": ""
    },
    {
        "title": "Would a persons correlation of -.127 be a very weak correlation or no correlation?",
        "author": "emmaserena21",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8etsfo/would_a_persons_correlation_of_127_be_a_very_weak/",
        "text": "",
        "created_utc": 1524665030,
        "upvote_ratio": ""
    },
    {
        "title": "What's the significance of the James-Stein Estimator's positive-part dominating its usual class of J-S estimators?",
        "author": "ChaseTheMoonLikeFire",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8et681/whats_the_significance_of_the_jamesstein/",
        "text": "I understand that the positive-part of the James-Stein estimator dominates the usual James-Stein estimator, but what's the point of it?\nI'm going to have to report on this for my Bayesian Inference class, and I can't find anything online that tells me the importance of this discovery/proof. I don't need any in-depth answer (or rather, I most likely won't be able to understand it).  Thanks a lot in advance!",
        "created_utc": 1524659445,
        "upvote_ratio": ""
    },
    {
        "title": "Confidence vs Credible Interval",
        "author": "strideside",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8erwwu/confidence_vs_credible_interval/",
        "text": "I'm trying to grasp the differences between frequentist and bayesian statistics, and came across [this particular explanation about confidence intervals](https://www.reddit.com/r/explainlikeimfive/comments/6ke8zx/eli5_can_someone_explain_confidence_interval_in/djleney/).  \n\nThis seems like the correct explanation, but I was more curious then using that example, would it be correct to say that if we were to calculate the credible interval, it can be interpreted as:\n&gt; There is a 95% chance the probability of heads is between 0.49 and 0.51.\n\n&gt; Given my interval, there's a 95% chance it contains the correct value of a",
        "created_utc": 1524643734,
        "upvote_ratio": ""
    },
    {
        "title": "Sample Mean / Population distribution question",
        "author": "TonedTony",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eqzmy/sample_mean_population_distribution_question/",
        "text": "Hey guys,\n\nI'm not even sure I know what I'm asking but, this is from my textbook chapter on testing sample means / sampling distribution of the mean. I'm no stats whiz yet so don't kill me.\n\nWhy is there less variability in the sampling distribution of the mean than the population distribution in the picture? Any insight appreciated!\n\n[https://ibb.co/iUampH](https://ibb.co/iUampH)",
        "created_utc": 1524631705,
        "upvote_ratio": ""
    },
    {
        "title": "Question about dummy variables for regressions",
        "author": "thrism",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eqzmc/question_about_dummy_variables_for_regressions/",
        "text": "So I am trying to run a regression to estimate how many orders to expect on a given day. One of the things I am testing is day of the week. So I set up a dummy variable for monday, tuesday, wednesday, thursday, saturday, and sunday (friday being the best day of orders and so left out). When I run the regression on excel. I get good p-values on everything execpt wednesday and thursday.\n\nDoes this mean that I can not use day of the week in my model at all? or do I just take out those two days?",
        "created_utc": 1524631701,
        "upvote_ratio": ""
    },
    {
        "title": "Desperately trying to understand Cohen’s d formulas for effect size, please help!",
        "author": "jsm1n",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eqpwt/desperately_trying_to_understand_cohens_d/",
        "text": "Hi, I’m a college student and I’m having a really hard time understanding when to use different Cohen’s d formulas. \nMy prof gave us 3 formulas to calculate Cohen’s d (on the left of the picture), but when I checked the answers of a worksheet he gave us, I noticed he used formulas I’d never seen before (on the right side of the picture). When do I use these formulas? \nPlease help, thanks!\n\n[Formulas](https://ibb.co/mw6Ubx)",
        "created_utc": 1524628798,
        "upvote_ratio": ""
    },
    {
        "title": "ELI5 Bayesian Linear Regression",
        "author": "HeckleMonster",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eqjrp/eli5_bayesian_linear_regression/",
        "text": "Assume I'm a 5 year old who's taken an intro stats course. What is the Bayesian approach to simple linear regression, as compared to the frequentist approach? For linear regression, is the prior distribution a distribution of coefficients (slope, intercept)? If not, then what is it? How should I pick one? Is there an easy way to do this in R? Sorry about all the questions but these are just the kinds of things I'm hoping a summary of Bayesian recession would address. Thank you!",
        "created_utc": 1524627073,
        "upvote_ratio": ""
    },
    {
        "title": "Will you hit more red/yellow lights driving the exact speed limit or 10 mph above it?",
        "author": "neverbeast",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eq3h1/will_you_hit_more_redyellow_lights_driving_the/",
        "text": "My friend says you will miss more red lights if you drive faster, but I say there are too many variables and you're just as likely to get to a red light sooner by driving faster so it's the same either way.\n",
        "created_utc": 1524622626,
        "upvote_ratio": ""
    },
    {
        "title": "Using two continuous variables sets to predict a yes or no outcome.",
        "author": "cerealfornights",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eppfj/using_two_continuous_variables_sets_to_predict_a/",
        "text": "Hello Ask Statistics, \n\nI am new to statistics. I want to use two continuous variables to predict a yes or no outcome and was hoping for suggestions for a statistical test. \n\nExample data\n\nPerson 1  10yo    50lbs   yes \n\nPerson 2  12 yo   54lbs  no\n\nI have this info for \\~150 people\n\nAfter looking through this  \\([https://stats.idre.ucla.edu/other/mult\\-pkg/whatstat/](https://stats.idre.ucla.edu/other/mult-pkg/whatstat/)\\) I assumed that I had one dependent variable. I tried to fit my data into the first four tests, but I didn't think any of them fit. \n\nThank you in advance!\n\n\\*Disclaimer, I don't know how much 10yo are supposed to weigh",
        "created_utc": 1524618878,
        "upvote_ratio": ""
    },
    {
        "title": "How could you tell if there is a statistically significant difference in the standard deviation of two groups?",
        "author": "Stevonz123",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eovqg/how_could_you_tell_if_there_is_a_statistically/",
        "text": "",
        "created_utc": 1524611466,
        "upvote_ratio": ""
    },
    {
        "title": "Not sure what I can do stats on",
        "author": "jasonale",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eootf/not_sure_what_i_can_do_stats_on/",
        "text": "Hi!\nI'm writing my PhD thesis right now and my project was determining if antibodies raised in animals against a viral vaccine was protective and to map where on the protein these antibodies bound to. \nI'm pretty ignorant about statistics and I don't want to be caught with my pants down during my defense so I have an example.\nIn these experiments I tested two goats (and two different bleeds one before vaccination one after) up to 2-4 separate experiments in singlicate to see if goat antibodies could block the virus from infecting the cell. Is there anything I can test here? Is 3-4 replicates enough to do a t-test to show that post-vaccination was higher than pre-vaccination in a single goat? Because I know that I can't do that with goats because there was only two. In other experiments we had 8 mice in each group so I could do stats on them but goats are big and expensive haha.\n\nThanks so much! ",
        "created_utc": 1524609995,
        "upvote_ratio": ""
    },
    {
        "title": "(Possibly) Basic question regarding Poisson distribution from an EE major.",
        "author": "winterfellow_",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eoo00/possibly_basic_question_regarding_poisson/",
        "text": "I believe this should be the right place to ask this question since it is not an actual homework, but the mods can delete it if they think otherwise.\n\n\nI'm currently working on a project regarding voltage sags (dips) assessment using stochastic methods. One of the variables (probably the most important one) is the total amount of years a simulation must go through (think of it as an outer for-loop for the algorithm I'm implementing). I've been using an equation from a paper where I can find the total amount of years by providing a determined accuracy and the frequency per year of the event. Apparently it uses Poisson distribution. I'm not sure if the application is relevant so I won't extend much here.\n\n\nI'm curious to know how the author came up with the equation as he mentions that it's \"basic statistics\". My background in statistics is poor as I took a basic class several year ago so I remember almost nothing. I'm wondering if anyone could show me how to find this equation or give directions so I can find it myself.\n\n\nHere is the equation:\nhttps://imgur.com/a/NruZobb\n\n\nThe paper is named: \"Stochastical and Statistical Assessment of Voltage Dips\". You can find it on IEEEXPLORE database.\n\n\nPS: Sorry for any mistake. English is not my native language.",
        "created_utc": 1524609810,
        "upvote_ratio": ""
    },
    {
        "title": "Ran an experiment. Have data. Please help me decide how to analyze it.",
        "author": "terusama",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eofic/ran_an_experiment_have_data_please_help_me_decide/",
        "text": "I actually posted here not too long ago, but I realized when I posted before I was too unclear about the nature of my experiment and I needed to ask more follow-up questions. So I'm going to describe an experiment that is essentially just like mine.\n\nLet's say I want to test whether or not the usage of the word \"like\" has any impact on whether or not a participant will trust the person using the word. So, I design an experiment where three people are selling oranges. Each trial, the participant must choose from one of the three people to buy oranges from. The first person never says \"like\", the second person says \"like\" 10% of the time, and the last person says \"like\" 20% of the time. There are 120 trials. \n\n&gt;What test should I run to show a relationship between the number of times a person says \"like\" and how frequently the participant buys oranges from that person? (I thought about doing a correlation or simple linear regression.) \n\n&gt;How should I run this test? Are there considerations for how my dependent variable is number of picks, but the times one seller is picked deprives the other sellers from being picked (i.e. the number of times any one seller is picked is related to the number of times other sellers are picked, within-subject?)",
        "created_utc": 1524607743,
        "upvote_ratio": ""
    },
    {
        "title": "Question about applying test to my survey data",
        "author": "I_HATE_LANDSCAPES",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eodh3/question_about_applying_test_to_my_survey_data/",
        "text": "I'm a little lost. This is all pretty new to me, so I don't even really know how to search this sub for answers.\n\nI have a 22-question survey with 147 respondents giving likert answers.\n\nI want to see what statistical differences there might be between male and female respondents. I also want to test to see the differences between respondents based on income and again based on education.\n\nI was trying to apply ANOVA, but I'm afraid I'm skipping something.\n\nDo I have to do this for each question or is there a way I'm supposed to prepare my data to make it more manageable and meaningful?",
        "created_utc": 1524607265,
        "upvote_ratio": ""
    },
    {
        "title": "Is this the most statistically unlikely event(s) to have occurred in human history?",
        "author": "rspenmoll",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8enrtj/is_this_the_most_statistically_unlikely_events_to/",
        "text": "Dylan McWilliams, has in the last three years, been bitten by shark, rattlesnake, and attacked by a bear in the last three years, which apparently have a combined probability of 1/893.35 quadrillion, according to [this article](https://news.nationalgeographic.com/2018/04/odds-of-man-bit-shark-bear-snake-dylan-mcwilliams-animals-spd/). I realize there is probably no real answer this question, but his seemingly incredibly bad luck got me wondering and I wanted to ask just in case. Has there been any event or series of events in human history known to have happened that have had a calculated event probability of lower than the 1/893.35 quadrillion figure mentioned in the article?\n*Edited to correct punctuation and add edit summary.",
        "created_utc": 1524602444,
        "upvote_ratio": ""
    },
    {
        "title": "Question on how to state null and alternative hypotheses?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8emodv/question_on_how_to_state_null_and_alternative/",
        "text": "[deleted]",
        "created_utc": 1524594224,
        "upvote_ratio": ""
    },
    {
        "title": "Regression Analysis method question",
        "author": "lookforward24",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8emfim/regression_analysis_method_question/",
        "text": "I have been given a dataset containing 50 observations and 2 data elements (#IP, #OP) and have been asked the results of the following 2 regression models:\nModel 1: OP=A+BxIP\nModel 2: OP=BxIP\nI don't know how to do model 2, does it mean that no intercept is required? \nAlso anyone knows a book for basic regression analysis skills.\nThanks and look forward to hearing from you",
        "created_utc": 1524592403,
        "upvote_ratio": ""
    },
    {
        "title": "Statistics for the Layperson",
        "author": "XtraSpiceyKetchupPlz",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8emdcl/statistics_for_the_layperson/",
        "text": "Hey all, new account so that information cannot be deductively derived from my usual.\n\nI'm a subject matter expert in my field but I am not a statistician. I do not have a great working knowledge of statistics aside from some very preliminary stuff. I have a specific situation I'm trying to use statistics for and I already have a hypothesis. The information I am analyzing is somewhat sensitive so I am inventing a fictitious example to approximate what I'm looking for. Please don't take the example too literally, it has nothing to do with law enforcement.\n\nSituation: Crime sites have been identified all over the City of Wherever over the past 10 years. 5 years ago, a special law enforcement program started looking for evidence of drugs in high crime areas. Evidence ranged from weak \\(paraphernalia\\) to very strong \\(actual presence of baggies, stockpiles of drugs, etc\\). For the purpose of this study, there is no differentiation between weak and strong evidence \\- it is merely evidence. Empirically speaking, at least 40&amp;#37; of the time when drugs are found by the police task force, there is a home within 200 yards where a criminal is making the drugs. Sometimes the drugs are found before the cops get a call about a home potentially being a crime site where thugs are in the act. Other times, the drugs are found after a gang safehouse has been vacated and the drug lab is no longer active.\n\nAnother analyst has already partially correlated the presence of drugs to the presence of police raids on criminal groups. However, I hypothesize that this might be skewed data because the raids are happening in high crime areas where the proximity of other, non\\-drug crimes is already high. Those crimes may or may not have anything to do with drugs, although it's hard to say and there are likely an unquantifiable amount of permutations that could connect or refute a connection between those criteria.\n\nMy primary hypothesis is that the presence of drugs is significant enough to point towards a likely \\(using the term in non\\-mathematical fashion here\\) proximity of a drug production house, a gang warehouse, etc. I'm looking to prove this mathematically aside from merely reporting that Whatever percent of drug finds were near the actual drug crime scenes.\n\nQuestion 1: Am I correct in assuming that only two criteria/fields are necessary? \\(Presence of drugs and Drug labs\\)\n\nQuestion 2: Is regressive analysis the best choice for this? Should I utilize a chi square? My data collection is not yet complete but I will have about 100\\-125 examples of data to work with.\n\nThanks in advance!",
        "created_utc": 1524591969,
        "upvote_ratio": ""
    },
    {
        "title": "Question about interpreting Adjusted R squared values and standardized coefficients.",
        "author": "ResearchRelated",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8em94n/question_about_interpreting_adjusted_r_squared/",
        "text": "Hello, I'm writing my first big medical research paper, and I have been trying to understand statistics along the way. \n\nSo, I have results from two regression models I am trying to write about. IV 1 includes 2/3 options. IV 2 includes access to 3/3 options.\n\nIV1 has a higher adjusted R squared, but a lower standardized coefficient. I know what to write when both are higher/lower, but what do I state when R squared is higher but standardized coefficient is lower?\n\nFor context, IV2 should be stronger as it is all inclusive. If you need more context I am happy to provide it, I just didn't want to bore or distract from the question. \n\nThank you all in advance, and if there is another sub I should post to please let me know. \n\nEdit: I am a noob and said DV everywhere I meant IV. My bad. ",
        "created_utc": 1524591112,
        "upvote_ratio": ""
    },
    {
        "title": "Question on evaluation",
        "author": "Losttouch1993",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8elurd/question_on_evaluation/",
        "text": "Hi, there are many ways to evaluate the performance of a model.\n\nA question I always raise in class and get differing answers is the use of in-sample VS out-of-sample metrics for evaluation.\n\nWhy do we use in-sample measures like Rsq to measure model performance when we have out-of-sample indicators like cross-validation errors to measure performance?\n\nSorry if the question offends any statisticians but I have received conflicting answers from different professors and have yet to receive one that I am able to reconcile.\n\nThank you in advance!",
        "created_utc": 1524588133,
        "upvote_ratio": ""
    },
    {
        "title": "Help with Multiple Regression Analysis",
        "author": "ipagera",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ejwjd/help_with_multiple_regression_analysis/",
        "text": "Guys, how would one interpret the results in the model summary from SPSS and the Beta and B output in a multiple regression? What if I have 8 IVs but only 2 of them are significant in their correlation with the DV? (The R squared I get is 0.629 and the adjusted R squared is .470 in the model summary with a significance on the ANOVA test of aprx 0.016. Also do I report all variables or only the significant ones in the correlational testiting? What is the multiple regression telling me if the model is a significant and the adjusted R squared is .47 but the only two variables are significant in the Pearson's tests of correlation? \n\nThank you in advance!",
        "created_utc": 1524571824,
        "upvote_ratio": ""
    },
    {
        "title": "Hello! In need of advice regarding violated assumption of Pearsons Chi Square Test. SPSS.",
        "author": "IamNowUpsideDown",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ejmer/hello_in_need_of_advice_regarding_violated/",
        "text": "Hello! I am wondering what the correct course of action is when the assumption for a Chi Square test,  that less than 20&amp;#37; of the cells in a cross\\-tabulation should have an expected count less than 5, is broken. I am using SPSS.\n\nI have found conflicting answers to what to do next. Can I simply use the likelihood ratio that is listed below the Chi Square test instead? If so, can I also use the Phi or Cramer's V tests \\(for measuring the strength of the association\\) that derived from the data that violated the assumption in the first place? If not, how can I measure the strength of the association?\n\nAlso, I am confused as to the significance of the degrees of freedom and how they relate to the critical value. Is the critical value simply the level of significance, aka 0.05? The degrees of freedom is 6 \\(for both chi square and likelihood ratio\\), how does that change my findings? Should the degrees of freedom somehow be included in how I interpret or report the data?\n\nHope someone can help! Thanks :\\)",
        "created_utc": 1524568642,
        "upvote_ratio": ""
    },
    {
        "title": "ANOVA - Degrees of freedom computation",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ejg1m/anova_degrees_of_freedom_computation/",
        "text": "[deleted]",
        "created_utc": 1524566455,
        "upvote_ratio": ""
    },
    {
        "title": "Is a MANOVA the best option?",
        "author": "_Pizza_Princess_",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ej4i1/is_a_manova_the_best_option/",
        "text": "I'm analysing an IV (each participant is rated 0-4) against two separate DV scores.\n\nEdit: I also looked at doing t-tests for each separate DV. ",
        "created_utc": 1524562002,
        "upvote_ratio": ""
    },
    {
        "title": "Proving the best of 3 testing methods, using one way ANOVA",
        "author": "spoerge",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eixx7/proving_the_best_of_3_testing_methods_using_one/",
        "text": "Data: I have 3 test groups using a different method of testing a website, which has produced a combined 36 unique errors.\n\nGroup A has 2 testers and using method A, find 17 and 19 unique errors respectively.\n\nGroup B has 3 testers and using method B, find 6, 9, 12 unique errors respectively.\n\nGroup C has 3 testers and using method C, find 8, 12, 16 unique errors respectively.\n\nQuestion: How do I prove which is the best method statistically? Cannot use Fisher Exact, bit would a one way ANOVA be sufficient.? If yes how would I interpret the results.",
        "created_utc": 1524559393,
        "upvote_ratio": ""
    },
    {
        "title": "ARIMA differencing query",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eisn0/arima_differencing_query/",
        "text": "[deleted]",
        "created_utc": 1524557158,
        "upvote_ratio": ""
    },
    {
        "title": "Fisher Exact Test",
        "author": "sentas2018",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eic2y/fisher_exact_test/",
        "text": "Test group A using T method finds 26 of the problem issues.\nTest group B using E method finds 28 of the problem issues.\n\nHow do I get the P value using Fishers Exact Test?\n\nIt should give P as being 0.786, but I am unable to find this.",
        "created_utc": 1524550728,
        "upvote_ratio": ""
    },
    {
        "title": "Unsure how to test my data - Mixed linear model?",
        "author": "Zetner",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ei74d/unsure_how_to_test_my_data_mixed_linear_model/",
        "text": "Hey everyone - I'd really appreciate it, if someone could help me out!  \n\nBackground: I am currently planning a clinical study, where I will administer active medication and a placebo drug. I will follow the patients for 8 weeks, obtaining data once weekly. My variables are measuring the degree of adverse reactions to radiation therapy.  \n\nI've calculated my sample-size based on the outcome on the 7th week data collection, for both of my three variables.  \n\nMy three variables are:  \n\n1) an ordered categorical grading-scale (0, 1, 2, 3 and 4)  \n2) a continuous scale  \n3) also a continuous scale  \n\nNow, my primary outcome (data at 7 weeks) will be compared between the active and placebo groups through either unpaired t-tests or Mann-Whitney U depending on if data are normally distributed.  \n\nMy question is, how do I compare the remaining data points for the two groups? I would like to investigate if the active treatment diminishes the degree of adverse reactions the patients receive from radiation throughout the 8 weeks.  \n\nI'm a bit lost here - Could this comparison be performed with an ANOVA? Would Friedman be better? A bio-statistiscian I spoke with briefly suggested a \"mixed linear model\", which I have no idea what is?  \n\nAlso, seeing as I am including patients, I will most likely have to deal with missing data at some point. From what little I understand, the mixed linear model would take missing data into account, but I have no idea how?  \n\nAlso: English is not my primary language, so some of the statistical terms might not be completely on point. Feel very free to ask for any clarification! - I don't know if educational background is relevant, nonetheless: I'm an MD, Ph.D.-student. Even though I've had a couple of large statistical courses, it just hasn't \"clicked\" in my head yet - statistical theory just won't stick..  \n\nAgain, any and all help is very much appreciated!  \nEDIT: Formatting",
        "created_utc": 1524548987,
        "upvote_ratio": ""
    },
    {
        "title": "How do I indicate this is monthly data in R?",
        "author": "zzzzz94",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eh1p6/how_do_i_indicate_this_is_monthly_data_in_r/",
        "text": "I have data that looks like this which R reads as two different variables (and the 484-500 are the observations numbers). Which is fine, but the left variable is obviously time, it's monthly data. How do I get R to recognize it as such, with only 1 variable (the right hand side column)?\n\n484 1999-04-01  80.856\n\n485 1999-05-01  80.889\n\n486 1999-06-01  80.906\n\n......\n",
        "created_utc": 1524536348,
        "upvote_ratio": ""
    },
    {
        "title": "AP Stats - Which Test is This?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8egud8/ap_stats_which_test_is_this/",
        "text": "[deleted]",
        "created_utc": 1524534462,
        "upvote_ratio": ""
    },
    {
        "title": "Help creating individualized error bars",
        "author": "wiseIy",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eg0kq/help_creating_individualized_error_bars/",
        "text": "Sorry if my formatting is off, I am brand new to Reddit. Essentially, I am trying to add error bars to this figure, but I each bar within the figure to have an individualized error bar based on the standard deviation. Neither google sheets nor excel has options to assign each bar its own value for the error bar. Can anyone help?\n\nHere are the raw data, with the individualized StDevs in parenthesis. My specific issue is that all the figures I am generating allow me to make error bars EITHER by language group or intentional and accidental, when what I need is an individualized error bar cell\\-by\\-cell. \n\nLanguage Group\t                     Intentional \t                       Accidental\n\nEnglish Monolinguals \t     4.84\\(1.68\\)\t                                5.12\\(1.24\\)\n\nEnglish\\-Spanish Bilinguals\t    4.74\\(1.71\\)\t                                4.3\\(1.58\\)\n\nSpanish\\-English Bilinguals     5.88\\(1.57\\)\t                                5.14\\(1.93\\)\n\nAgain, sorry if when I post this the formatting looks awful, and again I apologize if this is not an appropriate request for this community. I am just technologically stymied right now and am trying to generate nice figures for my thesis! Help me to graduate! Thanks!\n\nhttps://i.redd.it/up1z72kbuqt01.png",
        "created_utc": 1524526589,
        "upvote_ratio": ""
    },
    {
        "title": "Trying to understand how to setup some linear regression models on my data for analyses",
        "author": "iarcfsil",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8efxjb/trying_to_understand_how_to_setup_some_linear/",
        "text": "I've been trying to teach myself some statistics, specifically just linear regression the past few weeks, and am struggling to apply what I've learned to analyze a dataset I have. I'm using R and was able to clean the data set and create a model, but I don't think it's correct. I'd just like some guidance on how to setup my model and whatnot.\n\nSo the data looks like this: \n\nSchool | Year | Grade | #students | Overall Math Score| Math modeling % met or exceeded| Math supporting context % met or exceeded\n---|---|----|----|----|----|----|----\n610534| 2016\t| Mathematics Grade 3| 57|  67| 5.3%| 94.7%\n610534| 2016\t| Mathematics Grade 4| 60|  70| 8.3%| 91.7%\n610534| 2016\t| Mathematics Grade 5| 59|  90| 6.8%| 93.2%\n610534| 2015\t| Mathematics Grade 3| 57|  99| 5.3%| 94.7%\n610534| 2015\t| Mathematics Grade 4| 60|  97| 8.3%| 91.7%\n610534| 2015\t| Mathematics Grade 5| 59|  66|  6.8%| 93.2%\n\nThere's a bunch of data for several hundred schools, from the years 2015, 2016 and 2017. There was a policy implemented at 10 schools during 2016-2017 for specifically 5th grade (`Grade=\"Mathematics Grade 5\"`), so I'd like to analyze how effective the policy was. There are more columns in the data to reflect similar measurements to `math supporting context % met or exceeded). I'd like to create models to see:\n\n1. How those 10 schools performed during those years relative to other schools. I created a dummy variable as `1` for those schools during those years. So 20 records have the variable `treat=1`. The model I tried running in R was: `lm(df$Math.supporting.context..met.or.exceeded ~ df$treat + df$grade + df$year, data = df, model = TRUE)` EDIT: I tried the following, and it seems closer to what I think I'm trying to do here, but I'm definitely not quite there. First I filtered the original `df` into just having `grade == 'Mathematics Grade 5'`. THen I tried `lm(df$Math.supporting.context..met.or.exceeded ~ df$treat)` but that's giving me `NA` for all values for `treat`\n\n2. How the 6th grades at those schools performed in 2017 compared to all the other schools. I have no idea how to set this up.\n\n3. How do I see if the other output variables were effected? THere are about 10 more variables where I'd like to run a model so in addition to the model in point 1 above, I want to try `lm(df$other.output.variable ~ df$treat + df$grade + df$year, data = df, model = TRUE)`. Is there a way to run all different models simultaneously?\n\nI had [a thread from the weekend](https://www.reddit.com/r/AskStatistics/comments/8dx1bj/is_linear_regression_an_appropriate_approach_for/) but as you can see per my comments there, I'm still pretty stuck as to what to try and change. I'm completely lost as to how to use `Matchit` even though it seems to be the suggested package to use.",
        "created_utc": 1524525823,
        "upvote_ratio": ""
    },
    {
        "title": "The average age of observations in a forecast equation",
        "author": "MasonBo_90",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8efk49/the_average_age_of_observations_in_a_forecast/",
        "text": "Suppose I have a forecast equation Z at origin [T] that predicts (h) steps ahead, Z[T](h), such as \n\n Z[T](h) = 1/9(Z[T]+ 2xZ[T-1] + 3xZ[T-2]+ 2xZ[T-3] + Z[T-4])\n\nWhat is the average age of the observations in this forecast equation? \n\n................................................................................................................................................................\nMore context: the origin T is the moment in time where the prediction was made and the h the horizon - how many steps ahead - the prediction is for. \n\nSuppose the forecast equation above is for a monthly time series. You have data from December 2017 to April 2018. If you use all the information you have and make a prediction considering the last piece of information you have, your origin T would be April. Now, you may predict for one, two, or n-th months ahead. Usually, though, as new observations arise, the model is updated and new batch of forecast is done. ",
        "created_utc": 1524522518,
        "upvote_ratio": ""
    },
    {
        "title": "Need help interpreting these autocorrelation plots (made with python)! Hopefully they are clear...",
        "author": "MLbeginner96",
        "url": "https://i.redd.it/22p34fmlzpt01.png",
        "text": "",
        "created_utc": 1524516187,
        "upvote_ratio": ""
    },
    {
        "title": "What test would I do?",
        "author": "Corashan",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eerh8/what_test_would_i_do/",
        "text": "I am creating a survey to determine if respondents trust my brand. I have them give me an overall trust rating, 1 to 5 scale. Then I ask them various questions that get at what theory says to be components of trust (Fidelity, Competence, Honesty, Confidentiality, etc.), all on a 1 - 5 scale.\n\n\nWhat I would like to do is determine which of the components is most important (or most correlated) to the respondents' overall trust rating.\n\n\nWhat kind of analysis would I be looking to do?\nThanks in advance for your help!",
        "created_utc": 1524516068,
        "upvote_ratio": ""
    },
    {
        "title": "Bayesian Network - Inference by enumeration",
        "author": "djsnipy",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ectb0/bayesian_network_inference_by_enumeration/",
        "text": "I have the following network, with given CPT:\n\nhttps://i.stack.imgur.com/RffwR.png\n\n\nI'm given P(E|D) and P(E|¬D) but am trying to find P(E|A). I rewrote the question as:\n\nP(E|A) = P(E,A)/P(A). Now I am stuck finding P(E,A). It seems I would have to sum up the joint probabilities of P(E,A,...all combinations of other variables). Is that the right way/even possible? I'm still quite new to this so I'm uncertain if there's some way to massively simplify the problem using the graph structure or something.",
        "created_utc": 1524501263,
        "upvote_ratio": ""
    },
    {
        "title": "Limitations of converting ordinal data to continuous?",
        "author": "thatmorningperson",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ec7y7/limitations_of_converting_ordinal_data_to/",
        "text": "I am in a research project for class that is only allowing a bivariate analysis. My teacher said that we can treat ordinal data we collect as continuous when we enter it into SPSS. I know there are many disadvantages to this that can skew/bias/possibly ruin our data but could you list out to me why exactly it is a problem? Thanks!",
        "created_utc": 1524496663,
        "upvote_ratio": ""
    },
    {
        "title": "Should I use lagged variables? First answer $15 paypal!",
        "author": "humpingcamel",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ebuzk/should_i_use_lagged_variables_first_answer_15/",
        "text": "Hi so I need to run a regression asap.\n I am looking at camera sensor technology and its growth over time for DSLR/Mirrorless cameras compared to the growth of smartphones. (trying to prove that smartphone growth has slowed the sensor technology of DSLR/Mirrorless cameras) I have data from camera sensor tests over the last 10 years that describes each camera sensor by ISO, Dynamic Range, and Color Depth for low-price, middle-price, and high price DSLR's and sales numbers of smartphones each year over the last 10 years. I also have Net sales and Operating income data over the last 10 years for camera companies Canon and Nikon (to show they have less $ to invest in new sensor tech). \n\nI really do not care if the regression proves anything or is inconclusive, it just has to make statistical sense or I am going to be completely screwed.\n\nSo if you could explain to me what I should regress against what, etc. it could steer me on the right track.\n\nPaypal money will come by tomorrow night.\nThanks so much!\n",
        "created_utc": 1524493714,
        "upvote_ratio": ""
    },
    {
        "title": "Kruskal-Wallis test for showing features can discriminate the classes",
        "author": "ikaraas",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8eahty/kruskalwallis_test_for_showing_features_can/",
        "text": "Hi all,\nI'm working on a problem for classifying **3** gestures using the EMG signals obtained from muscles. \n\n* Each of the gestures has **6** trials of around **6-7s** duration.\n\n* Each trial is divided into multiple segments of some window length like(150ms with overlapping). The trials are performed by **10** individuals .\n\n* I've extracted **5** features from each segment.\n\n* Each classes/gestures may not have exactly equal number of observations/examples but it would be around 3600.\n\n*This is the background to check if all the assumptions for kw hold or not. I have the feature matrix as X (11000,5) and labels y(11000,1).*\n\nNow I would like to test statistically if each of the 5 features has the ability to discriminate 3 gestures.\nHence for each feature, my understanding is, to use KW test to check that if features coming from 3 gestures are significantly different, i.e. if p-value&lt;0.05 then the features may be able to differentiate the gestures.\nI coded in MATLAB for the first feature, like this:\n\n    [p,tbl,stats]=kruskalwallis(X(:,1),y)\n\nMy background in statistics is pretty weak, and this is what I've understood so far from reading different articles regarding kw test.\n\n* I would like to know, if my way of thinking for the statistical test to show the discrimination ability of features is correct or not.\n\n* secondly, is the code correct? I have found p=0 for each of the features I've tried. so I'm wondering if there's something wrong.\n\nI'm a non-native speaker so please ignore my grammatical mistakes.\nThank you very much for your valuable feedback.\n",
        "created_utc": 1524479980,
        "upvote_ratio": ""
    },
    {
        "title": "how to do a-priori and compromise power analysis for multinomial logistic regression in G*power",
        "author": "daisysneal",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ea72m/how_to_do_apriori_and_compromise_power_analysis/",
        "text": "Hi, i need to perform a power analysis to indicate the optimum sample size for my study, and then a compromise power analysis where my sample size is capped at 50. This is way beyond the scope of my course and i'm struggling to find clear guides online/in textbooks so was wondering if anyone could help please",
        "created_utc": 1524475936,
        "upvote_ratio": ""
    },
    {
        "title": "Controlvariables in panel data regression - problem?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8e9uun/controlvariables_in_panel_data_regression_problem/",
        "text": "[deleted]",
        "created_utc": 1524470906,
        "upvote_ratio": ""
    },
    {
        "title": "ELI5 James-Stein Estimator (Empirical Bayes)",
        "author": "ChaseTheMoonLikeFire",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8e9mzu/eli5_jamesstein_estimator_empirical_bayes/",
        "text": "Okay you don't have to talk like I'm 5, I have a fair grasp of the very basics of Bayesian Statistical Inference because I'm taking it this semester. I know the Bayes Theorem (of course), Posterior Distributions, conjugate priors, Posterior Predictive Distributions, and a bit about Loss and Risk (the semester is still ongoing and this is where we are so far). However I'm SO CONFUSED with the J-S estimator lessons I was reading on the internet. What is it really in simple language??",
        "created_utc": 1524467740,
        "upvote_ratio": ""
    },
    {
        "title": "What does it mean when the ANOVA result is significant, both post-hoc tests show no significance between any of the three groups?",
        "author": "FregeIsMyDog",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8e9efv/what_does_it_mean_when_the_anova_result_is/",
        "text": "Hello everyone, \n\nmy question is quite simple: What does it mean when the ANOVA result is significant, both post-hoc tests show no significance between any of the three groups? What can one reasonably say about this result? Can I claim that there is a tendency towards group differences? \n\nThanks!",
        "created_utc": 1524464542,
        "upvote_ratio": ""
    },
    {
        "title": "Imagine | Artificial Intelligence Without Statistics",
        "author": "LearningFromData",
        "url": "http://www.hashtagstatistics.com/2018/04/imagine-artificial-intelligence-without.html",
        "text": "",
        "created_utc": 1524452980,
        "upvote_ratio": ""
    },
    {
        "title": "Statistics major: Can't decide on specialization",
        "author": "novel_eye",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8e7d38/statistics_major_cant_decide_on_specialization/",
        "text": "I'm a freshman statistics major at a respected university for Statistics and Physics. I'm in a dilemma regarding what to minor in as both options have their own appeals. \n\n- Computer Science: Obviously, compsci will drastically increase my employability and expose me to some more powerful algorithms. Also, it'd be smart overall to be versed in languages beyond R and SAS. I'd love to take my python skills to a higher level of as well. As you may know, computer scientists are in high demand in the quant realm of the financial sector. \n \n- Astrophysics (Observational Astronomy): At my school there is a specialized route for statistics majors that goes into observational astronomy and the data analysis of astronomy. Nothing excites me more than physics, let alone astrophysics. I've spoken with two professors and both said that I can do undergraduate research once I am a junior without taking the minor courses. Still, I'm pretty interested in taking them regardless. My only concern is that employers will just think it's a neat thing on my resume and the effort will ultimately be pointless unless I pursue physics/astronomy on a graduate level. (I'm not again this but I'm not a physics major so I don't think its possible.)\n\nI'm hoping someone here with more experience can give me a fresh perspective on things. Taking a step back, I ultimately think that ASTR will be a good environment to develop my statistical skills in and still would prepare me fore any kind of statistical work. It's just a hard decision because I feel that compsci is just the more practical route to take.\n\nI'd be extra helpful if there are any astro-statisticians out there who could give me some encouragement :)",
        "created_utc": 1524442217,
        "upvote_ratio": ""
    }
]