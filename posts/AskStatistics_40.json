[
    {
        "title": "What are some good videos for grasping Statistical Inference?",
        "author": "mxhere",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8bf3t7/what_are_some_good_videos_for_grasping/",
        "text": "I'm still struggling to understand the concepts within Statistical Inference. Specifically I'm struggling with Bayesian Inference Estimations/Optimal Inferences, optimal unbiased estimation/hypothesis testing.",
        "created_utc": 1523429621,
        "upvote_ratio": ""
    },
    {
        "title": "stratified block randomisation",
        "author": "Jeshma",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8beekb/stratified_block_randomisation/",
        "text": "Already calculated sample size for my study with stratified randomisation technique included. Now we would like to change it as stratified block randomisation. Will this change affect the sample size.",
        "created_utc": 1523420816,
        "upvote_ratio": ""
    },
    {
        "title": "Interpreting fixed effects",
        "author": "irishrapist",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8be07r/interpreting_fixed_effects/",
        "text": "I used a logit regression. dv is ceo turnover, iv are ROA, TOBINSQ, EPS and Long term debt. Fixed effects are to control for the different industries in the sample.\n\noutput looks like this: https://imgur.com/a/Rtb0Z\n\nI know what to say about the results for my ind variables, but I don't know what to say about the fixed effects. There's only one industry with a p value &lt; 0.05, what does that mean? That the relation between the turnover and the ind variables is only significant in that industry?",
        "created_utc": 1523416479,
        "upvote_ratio": ""
    },
    {
        "title": "What resources have you found helpful for learning more about attribute bagging in the context of random forests?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8bdkum/what_resources_have_you_found_helpful_for/",
        "text": "[deleted]",
        "created_utc": 1523412280,
        "upvote_ratio": ""
    },
    {
        "title": "What resources do you recommend for picking parameters for Random Forests (specifically how many predictors to include)?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8bdi69/what_resources_do_you_recommend_for_picking/",
        "text": "[deleted]",
        "created_utc": 1523411564,
        "upvote_ratio": ""
    },
    {
        "title": "Calculating effect sizes on pretest - posttest1 - posttest2",
        "author": "LouSalomee",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8bbjox/calculating_effect_sizes_on_pretest_posttest1/",
        "text": "I'm currently writing a systematic review and it is driving me nuts. I'm trying to calculate effect sizes of several intervention studies and there is one, that has, as the title states, 2 posttests and I don't know how to deal with that. To calculate my usual cohens d - I use an online [calculator tool](https://www.campbellcollaboration.org/effect-size-calculato.html), which is already pretty elaborate, but it does not give me the possibility to calculate this monster! I have Means, and Standard Deviation as well as my p and n. \nIf this is a stupid question feel free to roast me, for I am as dumb as they come concerning statistics. \n",
        "created_utc": 1523395411,
        "upvote_ratio": ""
    },
    {
        "title": "Confusion regarding fitting and predicting time series models with an MA component.",
        "author": "LaurelLancesFishnets",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ba4ef/confusion_regarding_fitting_and_predicting_time/",
        "text": "How do you know the white noise series looks like? Isn’t it inherently random? Do forecasting models use seeds or is there something I’m missing?",
        "created_utc": 1523385566,
        "upvote_ratio": ""
    },
    {
        "title": "Discrimination testing problem",
        "author": "tealpeak",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b9nkq/discrimination_testing_problem/",
        "text": "I am trying to figure out the number of participants it would take (to choose the control) for the following example to have statistical significance (0.05). \n\nNot well read on statistics at all. Had a read around Chi-squared tests but hit a brick wall. Any help would be greatly appreciated!\n\nHere is the example:\n\n6 beers were provided. 1 of the beers was clearly labelled as the base beer (control) so as to be comparing the other beers to. Out of the 5 other beers, 1 beer was also a control but it's identity unknown to the participants out of the five beers. \n\nThe 4 different beers were all made to the same specification as the control, but at different times so had very subtle flavour differences. The main point of the test was to test the trueness to type of the 4 beers against the control, with a scale of 0-5 for certain sensory notes. \n\nHowever, there is also data as to which beer the participants thought the control was which I'm trying to explain.\n\n10 out of 20 participants correctly identified the control beer.\n\n",
        "created_utc": 1523382348,
        "upvote_ratio": ""
    },
    {
        "title": "Guidance in research analysis",
        "author": "throwawayolli",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b981d/guidance_in_research_analysis/",
        "text": "hello everyone - is there anyone willing to guide me through the statistical analysis of my data this week? I have a vague idea of what I need to do, but I am a bit unclear of the details. I am currently a doctoral student and my final research paper is due this coming Monday. It would be easier for me to call on the phone I think. Thank you so much!",
        "created_utc": 1523379494,
        "upvote_ratio": ""
    },
    {
        "title": "Best way to refresh myself in Statistics before my 1st year in Grad School?",
        "author": "manc4life",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b8vk8/best_way_to_refresh_myself_in_statistics_before/",
        "text": "I’m going for a Clinical Psychology PhD in the fall and will be taking 2 semesters of statistics. What’s the best way to review and prepare myself for this class? \n\nI’ve been out of undergrad for 4 years and am a little rusty on Stats and theories behind tests, etc. ",
        "created_utc": 1523377049,
        "upvote_ratio": ""
    },
    {
        "title": "If I have a plot f(x) = y, will y+1 be a sufficient statistic for the distribution?",
        "author": "RealMatchesMalonee",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b8bkh/if_i_have_a_plot_fx_y_will_y1_be_a_sufficient/",
        "text": "",
        "created_utc": 1523373381,
        "upvote_ratio": ""
    },
    {
        "title": "Expected value of a die roll",
        "author": "RealMatchesMalonee",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b81n8/expected_value_of_a_die_roll/",
        "text": "Expected value of a die roll comes out to be 3.5. We add the products of the number on the die face to the probability of them showing up face up.\n\nTake a six-faced die is rolled, that, instead of numbers, has a pear, an apple, a banana, a mango, a strawberry and a peach on its faces. What will be the expected value of this die roll? I hope what I'm asking isn't absurd.",
        "created_utc": 1523371314,
        "upvote_ratio": ""
    },
    {
        "title": "help with a GLM please ?",
        "author": "frewroo",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b7nn9/help_with_a_glm_please/",
        "text": "I have a regression of personality and min VO2 which is just about significant p = 0.0485, when i make this into a GLM and add sex as a factor, it is no longer significant even if i do not include an interaction, why is this? does personality have an effect on min VO2 or not? if some kind soul could explain i would be eternally grateful",
        "created_utc": 1523367632,
        "upvote_ratio": ""
    },
    {
        "title": "Decision tree variance",
        "author": "spaceape__",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b65kk/decision_tree_variance/",
        "text": "Hi,\n\nI have an assignment where I have to implement Random Forest in python and I am studying theory behind Random Forest.\n\nI found this [notes](http://www.math.mcgill.ca/yyang/resources/doc/randomforest.pdf) that seem quite exhausting.\n\nI have one doubt at this point:\n&gt;An average of B i.i.d. random variables, each with variance σ^2, has variance (1/B)*σ^2. If the variables are simply i.d. (identically distributed, but not necessarily independent) with positive pairwise correlation ρ, the variance of the average is...\n\nWhat do they mean for variance of the single classification tree B and how can I calculate it?\n\n\n",
        "created_utc": 1523350046,
        "upvote_ratio": ""
    },
    {
        "title": "Any good sampling design book other than Lohr's?",
        "author": "ChaseTheMoonLikeFire",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b5wwq/any_good_sampling_design_book_other_than_lohrs/",
        "text": "I'm an undergrad stats student just looking for a book about sampling design probably a bit less comprehensive than Sharon Lohr's. Something that I can quickly scan when studying. Suggestions?",
        "created_utc": 1523346530,
        "upvote_ratio": ""
    },
    {
        "title": "Not sure about what kind of analysis fits my data. Pathway dataset",
        "author": "keithwaits",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b5ubu/not_sure_about_what_kind_of_analysis_fits_my_data/",
        "text": "I have a dataset in which a couple of substance that are part of the same pathway are measured on multiple genotypes.\n\nSo in this pathway one substance is partly converted to the next and this new substance is again partly converted to a third substance.\n\nI want to try to model this process as best as possible to see if there are differences between the genotypes. But I am not sure how to do this.\n\nI can (and have) run an analysis per substance and I am thinking of running a Multivariate mixed model where I model all three substances simutaneously (following this article: http://www2.sas.com/proceedings/sugi23/Stats/p229.pdf).\n\nBut I feel that there should be a type of statistical analysis specifically suited towards this type of (pathway) dataset. Or is this allready achieved by choosing the correct co-variance structure in the multivariate mixed model?\n\n",
        "created_utc": 1523345433,
        "upvote_ratio": ""
    },
    {
        "title": "Question about Tree Pruning / Regression Tree Fitting Algorithm from ISLR",
        "author": "MulticulturalHound",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b5io0/question_about_tree_pruning_regression_tree/",
        "text": "Hi Guys,\n\nI'm currently going through Introduction to Statistical Learning in R and I'm a bit confused about the algorithm for fitting decision trees to solve a regression problem. The algorithm is described [here](https://imgur.com/a/E7E1X). I'm confused as to #1...how is the tree grown in the first place? Are you just selecting the decision that reduces RSS the most without an alpha parameter? And I'm confused about #3b... I'm confused as to how you're evaluating the MSE left out as a function of alpha...I was wondering if someone could explain what the actual function was? Thanks a lot for the help guys.",
        "created_utc": 1523341103,
        "upvote_ratio": ""
    },
    {
        "title": "Trying to explain why a regression model only works for one year",
        "author": "ivorybloodsh3d",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b4r20/trying_to_explain_why_a_regression_model_only/",
        "text": "I've been looking at electoral data from the US Presidential elections from 2000 to 2016. The DV is a binary on whether or not Republicans win the general election in a state; the main IV is a binary on whether or not Republicans have higher primary turnout than Democrats in a state. Using several other IVs, I have a model that works incredibly well at predicting the 2016 election (adjusted R^2 for 2016 is 0.95 versus &lt;0.20 for the other years), but doesn't work at all for any other election. I need a way to explain what is different about 2016 that caused it to be so special. \nOne of the most notable things in the data is that Republican primary turnout spiked in 2016, which could explain the increased significance of the net primary turnout as a predictor. So, I've looked into trying to explain the primary turnout change, which is where I'm getting a bit lost. I feel like I might be looking for a panel data model, but that works for variance over time, not over entity, but I'm still not sure if that's what I want. Time dummies don't really help, because they only show that there is a difference, not breakdown the difference to show \"Oh, 2016 had higher/lower x1, x2, and x3 compared which is why it had such higher republican turnout.\" It's also possible I am very much overthinking this and a normal regression or something even more simple would work fine. \nAt this point, I care a lot more about the differences between years than between states, but also need to be able to keep the states in mind. Is it possible to use the xtreg command in Stata and switch the id and time variables?\nBasically, I'm pretty lost about how exactly to go about this. \nI'm using Stata, by the way.\nNote: I have almost no background on Time Series, so I don't know if that would help or not.\n",
        "created_utc": 1523332332,
        "upvote_ratio": ""
    },
    {
        "title": "Would this questionnaire be considered single-stage cluster sampling or simplified random sampling?",
        "author": "DM08",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b2ahn/would_this_questionnaire_be_considered/",
        "text": "My research requires me to use a questionnaire that samples two completely different subsections of the population, mainly what people voted for in Brexit (Which is approximately a 50/50 split of the population). These are in my mind two very mutually exclusive options (Leave or Remain) which I think hits the criteria of single stage cluster sampling but I am unsure. Any help would greatly be apprieciated and please do tell me if this is idiotic, ive never been good at statistics.",
        "created_utc": 1523310281,
        "upvote_ratio": ""
    },
    {
        "title": "kernel of a gamma pdf?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b1j00/kernel_of_a_gamma_pdf/",
        "text": "[deleted]",
        "created_utc": 1523304406,
        "upvote_ratio": ""
    },
    {
        "title": "Sample size for ICC",
        "author": "asharogy",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b0xgn/sample_size_for_icc/",
        "text": "I would like to calculate the sample size to assess ICC for 6 raters at 90% power with 95% CI and Lower Confidence level at 0.75. Can I do it in R please provide the code",
        "created_utc": 1523299939,
        "upvote_ratio": ""
    },
    {
        "title": "Improving the quality of my dataset / report for more accurate description of the trend and avoidning missleading conclusions.",
        "author": "quelevator",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b0i09/improving_the_quality_of_my_dataset_report_for/",
        "text": "Hi,\nEvery four months I create a report for the purpose of telling the main trend of revenue and profits for the companies in a region. The data set consists of updated accouting data from 200-250 companies, selected by all companies in the region of 4500 companies. You can assume that the accounting data from the companies, are correct, and that the companies in the \"sample\" are quite representative (the only bias is that they use the same accounting firm).\nEverything presented from this period is compared (bar charts) with the period last year and two years back. What is presented in the report is:\n\na)% of companies increased and reduced revenue.  \nb) Average income for all companies  \nc)% of companies increased and reduced earnings  \nd)% of companies positive results  \ne) Average profit  \n\nTwo of the industries count for about 50% of the companies - so they are given separate analysis using the same method a) - e)\nSo my question is: what is your intuition about how to improve the quality of this report / what will you look for testing the data / what to do to ensure that the report does not give misleading conclusions.\n\nThe analysis is done in Excel and I have no plans to change just that:)\nThank you for all that can guide me in the right direction!\n\nEdit: companies with less than $200t in revenue and more than ~~$500t~~ $5 000t is left out. Over time companies that no longer furfill the criterias are replaced.  ",
        "created_utc": 1523296794,
        "upvote_ratio": ""
    },
    {
        "title": "How do I go about algebraically differencing a time series?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8b0ci8/how_do_i_go_about_algebraically_differencing_a/",
        "text": "[deleted]",
        "created_utc": 1523295667,
        "upvote_ratio": ""
    },
    {
        "title": "Can someone tell me if these residuals are ok? If not why?",
        "author": "Takeurvitamins",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8az88c/can_someone_tell_me_if_these_residuals_are_ok_if/",
        "text": "https://mokacytle.tumblr.com/post/172760751322\n\nI'm trying to visualize my data and it's kind of messy. I was thinking maybe I need to transform the data, but the residuals from this ANCOVA are normally distributed, so I'm not sure if I should do anything to them.\n\nIf I have a really low R squared (0.05) for the model, is that just all there is, or can I do something to fix it? To give you an idea of what I'm doing, I'm comparing the growth of two species against the water flow they experienced. The Ancova says there was an effect of species, but not of water flow. Species 1 has an R squared of 0.03, and species 2 has an R squared of 0. \n",
        "created_utc": 1523287316,
        "upvote_ratio": ""
    },
    {
        "title": "1st year out of college, looking to grow as a statistician",
        "author": "saxman95",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8az77g/1st_year_out_of_college_looking_to_grow_as_a/",
        "text": "Hi,\nI graduated in 2017 with a math and economics major. I currently work as a data analyst and am looking to develop skills such as data mining, machine learning and advanced analysis. I have a solid math foundation and have been trying to take online courses in ML to help progress but advice from seasoned statisticians and mathematicians would be much appreciated. Thank you.",
        "created_utc": 1523287117,
        "upvote_ratio": ""
    },
    {
        "title": "How can we determine the sample size from an unknown population?",
        "author": "opkyei",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ax5fz/how_can_we_determine_the_sample_size_from_an/",
        "text": "",
        "created_utc": 1523265957,
        "upvote_ratio": ""
    },
    {
        "title": "Handling negative share (percentage)",
        "author": "JonnyRobbie",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8awtkw/handling_negative_share_percentage/",
        "text": "I have some time series revenue data for several subjects. I then compute a simple market share by dividing one series by the sum off all the series (for each time separately).\n\nNow the problem is that there can me some 'returns' which manifest as a negative value in the revenue.\n\nWhat is the most logical/consistent way to handle such negative 'share'?",
        "created_utc": 1523261047,
        "upvote_ratio": ""
    },
    {
        "title": "Any advice for a freshman Statistics major?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8autgy/any_advice_for_a_freshman_statistics_major/",
        "text": "[deleted]",
        "created_utc": 1523237815,
        "upvote_ratio": ""
    },
    {
        "title": "Are variation and spread synonyms?",
        "author": "2001blader",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8au6es/are_variation_and_spread_synonyms/",
        "text": "This was a question on my quiz, and all my research is confusing me more, since different sources have different answers. ",
        "created_utc": 1523231673,
        "upvote_ratio": ""
    },
    {
        "title": "Prediction accuracy of binary outcome events",
        "author": "TartarSource",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8atvn7/prediction_accuracy_of_binary_outcome_events/",
        "text": "I have a series of chance based predictions along with a corresponding series of what actually happened. For example, on Monday, the weather forecast gave a 20% chance of rain on Tuesday. On Tuesday it did rain.\n\nCan someone please point me in the direction of a technique that could be applied to infer the accuracy of the predictions?\n\nThanks you very much.",
        "created_utc": 1523228839,
        "upvote_ratio": ""
    },
    {
        "title": "Graphing Help",
        "author": "mF_Huffy",
        "url": "https://www.reddit.com/r/MathHelp/comments/8at7fs/graphing_help/",
        "text": "",
        "created_utc": 1523228474,
        "upvote_ratio": ""
    },
    {
        "title": "I have an intricate euchre (card game) stats scenario",
        "author": "photographyhelp",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ato8j/i_have_an_intricate_euchre_card_game_stats/",
        "text": "Hi, \n\n\nI play a partner card game called euchre which is a variation on whist (think hearts/spades/bridge) the main difference is that the high cards are the jacks for the color of the suit called trump. Link to [euchre rules](http://www.dummies.com/games/card-games/euchre/the-basics-of-playing-euchre/). \n\n\nSo here's my situation. I'm trying to figure out which would be statistically better, to go alone (to play without a partner) in spades or clubs, given this particular hand:\n[screen shot of the euchre hand in question.](https://imgur.com/EIu0DkG)\n\nNormally, I would say clubs, because going alone would give me four clubs and a guaranteed point. But I was wondering if going alone in spades might actually be better because the off suit cards would be a k/10 and more likely to go through than a singleton off suit 9. Or would the chances of getting set outweigh the possibility of getting four points? Should you always go alone in the suit you have four trump or risk getting set for a better probability of making all five tricks, and therefore four points? Thoughts?\n\nIf you guys can't assist, could you point me in the right direction or show me how to calculate it myself? Or if I'm posting in the wrong place can you direct me? \n\n\nThanks",
        "created_utc": 1523226994,
        "upvote_ratio": ""
    },
    {
        "title": "Type II Error Question",
        "author": "pmpforever",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8at79m/type_ii_error_question/",
        "text": "I am having trouble calculating the type II error in the following question from my textbook:\n\n&gt;Q: A soft-drink machine is regulated so that the amount of drink dispensed is approximately normally distributed with a mean of 200ml and a standard deviation of 15ml. The machine is checked periodically by taking a sample of 9 drinks and computing the average content. If *x* falls in the interval 191 &lt; *x* &lt; 209, the machine is thought to be operating satisfactorily; otherwise, we conclude that u != 200 ml.\n&gt;\n&gt; a) Find the probability of committing a type I error when u = 200.\n&gt;\n&gt; b) Find the probability of committing a type II error when u = 215.\n\nI solved a) by using the CI provided to find my critical value and alpha. The solution being 0.0718.\nHowever, I don't know what approach to use for b).  I assume my null hypothesis H0 is 191 &lt; *x* &lt; 209. But I do not know how to test this when u is no longer centered in this range. The solution provided for b) is 0.1151\n\nThanks",
        "created_utc": 1523222947,
        "upvote_ratio": ""
    },
    {
        "title": "I’ve been asked to present a “baseline demographic”. What is it?",
        "author": "NT202",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aszaj/ive_been_asked_to_present_a_baseline_demographic/",
        "text": "I’m studying nutrition at university. I’m in first year, and We’re currently conducting a study to test the efficiency of carbohydrate sports drinks as an ergogenic aid.\n\nNever done a great deal of statistics before but I’ve managed to learn a fair bit of it so far. \nI’ve been told (over email) I need to the “baseline demographics” and “baseline differences/similarities” for the results section of my paper, but I don’t know what that is. My lecturer is now away for a few days so I thought I’d ask on here so I can get on with it.\nI know it’s going to involve me presenting whatever it is in some sort of graph or table using SPSS, but exactly *what* data needs to be in there I don’t know.\n\nThanks! :) ",
        "created_utc": 1523221064,
        "upvote_ratio": ""
    },
    {
        "title": "You’re usually a chill person, but what are you totally anal about?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8asino/youre_usually_a_chill_person_but_what_are_you/",
        "text": "[deleted]",
        "created_utc": 1523217284,
        "upvote_ratio": ""
    },
    {
        "title": "Beating the odds.",
        "author": "NotAlsoShabby",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8asdkc/beating_the_odds/",
        "text": "Hi ya’ll,\n\nI’ve been knocking a thought around in my head for a while and would like some other opinions.\n\nSay there’s a car crash and everyone survives. Or there’s a tornado but your home isn’t affected. Or say you’re walking down the sidewalk and a huge tree topples over but lands beside you.\n\nI see these things on the news everyday, these “close calls”. I am not a statistician, or a math major, or even good with numbers larger than what’s in a 6 pack. \n\nBut it seems to me, when people say ‘Beating the odds’ to describe these situations, I don’t think that’s what is really meant. \n\nWouldn’t you be beating the odds if you got killed by an unlikely event, not surviving it? Or, by the laws of language in statistics, even if it is likely or not, are you still always beating the odds? \n\n",
        "created_utc": 1523216190,
        "upvote_ratio": ""
    },
    {
        "title": "Ordinary least squares on a binary response and multiple binary predictors",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8asc1v/ordinary_least_squares_on_a_binary_response_and/",
        "text": "[deleted]",
        "created_utc": 1523215859,
        "upvote_ratio": ""
    },
    {
        "title": "I have a discrete random variable X, for which I would like the pmf. Is there a method for finding it?",
        "author": "GetFlyOnMyOwnSupply",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aqs6s/i_have_a_discrete_random_variable_x_for_which_i/",
        "text": "I'm seeking something similar to Kernel Density Estimation for continuous variables.",
        "created_utc": 1523202695,
        "upvote_ratio": ""
    },
    {
        "title": "Looking for techniques to do linear regression or ML model of sparse, discrete time series events (interventions) versus a continuous outcome.",
        "author": "uberdev",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aqrax/looking_for_techniques_to_do_linear_regression_or/",
        "text": "I am trying to model the effect of an intervention (e.g., taking a pill) on a continuous outcome (e.g., pain level). The features are discrete binary events in time series. Here's an example of how the data might look:\n\n    time   took_pill     pain_level\n    ---------------------------------\n    1                         4.1\n    2        true             4.0\n    3                         4.2\n    4                         3.1\n    5                         2.8\n    6                         2.6\n\n\nIn this simple example, I'm trying to capture the fact that the intervention (the subject took a pill) at time t=2 led to a decrease in pain at time t={4..6}. \n\n\nHere are some options I am considering:\n\n1. Apply a decay function (e.g., Gaussian, exponential) to the binary event to create a continuous feature (took_pill_decayed), and do time series regression of pain_level ~ took_pill_decayed\n\n2. Aggregate both indep and dep variables to longer time windows that would capture both the event and the outcome (say, 6-hour windows). Make a \"sliding window\" for each time step. \n\n\nWould love any other ideas!\n",
        "created_utc": 1523202475,
        "upvote_ratio": ""
    },
    {
        "title": "Which test is correct for my data?",
        "author": "totaledbaker",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aqq8a/which_test_is_correct_for_my_data/",
        "text": "Hello! Working on running my statistics and am kinda stuck here on whether the a T-test is correct for my data set.\n\nI am trying to determine if there is a correlation between number of cases observed \"observed incidence\" and distance one is away from a location termed \"Rountrip distance\"\n\nI've attached a picture of my data. Any help on what I should run would be greatly appreciated!\n\nhttps://imgur.com/a/jItjy",
        "created_utc": 1523202219,
        "upvote_ratio": ""
    },
    {
        "title": "Is this statistical statement about the frequency of crocodile attack correct?",
        "author": "Markdd8",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ap069/is_this_statistical_statement_about_the_frequency/",
        "text": "Speaking primarily about the Saltwater Crocodile, a species (along with the Nile crocodile) known to be exceedingly dangerous to man.\n\nThe website CrocBITE writes:  \"Attacks on humans by crocodilians are, statistically speaking, extremely rare. For instance, going swimming in northern Australia means you are roughly a hundred times more likely to drown than to be bitten by a crocodile.\"\n\nThe Saltwater is the dominant crocodile species in N. Australia.\n\nhttp://www.crocodile-attack.info/about/human-crocodile-conflict  (Attack Statistics)\n\nIn a 2012 commentary that distinctly seems to contrast, Grahame Webb, Charles Darwin University,  writes: \"There is no way of avoiding nor sugarcoating the predatory nature of saltwater crocodiles. If you dive off the Adelaide River bridge, 60 km east of Darwin’s city centre, and start swimming, there is 100% chance of being taken by a saltwater crocodile.\"\n\nhttps://theconversation.com/crocodile-culls-wont-solve-crocodile-attacks-11203\n\n\nIt seems accurate to say that if people entered Saltwater Crocodile habitats with the same lack of concern shown by people entering the ocean (where sharks might be a danger), the death rate from crocodile attack would skyrocket.\n\nIsn't the \"statistically...extremely rare\" statement problematic? \n\nShark attack is statistically rare, based on the frequency with which people swim in proximity to sharks without problem.   Much evidence suggests that people are not regularly swimming near Saltwater Crocodiles.  \n",
        "created_utc": 1523180802,
        "upvote_ratio": ""
    },
    {
        "title": "Likelihood ratio",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8anxfl/likelihood_ratio/",
        "text": "[deleted]",
        "created_utc": 1523163932,
        "upvote_ratio": ""
    },
    {
        "title": "What is the difference between: (t-critical * SD) and (t-critical * SE)?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8alyem/what_is_the_difference_between_tcritical_sd_and/",
        "text": "[deleted]",
        "created_utc": 1523142923,
        "upvote_ratio": ""
    },
    {
        "title": "log(y) = 2.94 + 4.36*x &amp; R^2 = .71. error=?",
        "author": "Sageo3000",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8alvy2/logy_294_436x_r2_71_error/",
        "text": "If i have the equation\nlog(y) = 2.94 + 4.36*x\n\nand I know the R^2 of the model is .71\n\nCan I deduce a value for error? ",
        "created_utc": 1523142248,
        "upvote_ratio": ""
    },
    {
        "title": "Non-full rank model estimation",
        "author": "maxdn",
        "url": "https://i.redd.it/sstnfkgp3kq01.jpg",
        "text": "",
        "created_utc": 1523137388,
        "upvote_ratio": ""
    },
    {
        "title": "Complex analysis - has anyone here taken this? Any use for statistics?",
        "author": "linyeah",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8alad1/complex_analysis_has_anyone_here_taken_this_any/",
        "text": "It seems as though it would be of pretty limited use, or at least far less use than many other things (perhaps discrete algorithms, optimisation and so on would be considered more 'use' than complex analysis)\n\nI'm curious if anyone has taken it and found it to be useful for statistics, and if so, how. \n\nThanks",
        "created_utc": 1523136875,
        "upvote_ratio": ""
    },
    {
        "title": "Finding MSE for an arbitrary value of the constant L.",
        "author": "maxdn",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8al9a6/finding_mse_for_an_arbitrary_value_of_the/",
        "text": "Linear model  y=Xb+e, N(0, sigma^2 I) where X is n x p. \nRecall that:\nsigma ^2 = SSE/ n - l\nMean square error of an estimator T of a parameter theta is E(T - theta) ^2 --&gt; Var(T) +bias(T) ^2 where bias(T) =E(T) - theta.\nFind the mean square error of sigma^2= SSE/n-l =(y^T (I-H) y)/n-l for an arbitrary value of the constant L and the mean square error when L=p",
        "created_utc": 1523136618,
        "upvote_ratio": ""
    },
    {
        "title": "Is this is appropriate use of composite score?",
        "author": "ultramurph",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8akk9v/is_this_is_appropriate_use_of_composite_score/",
        "text": "Hi everyone, let me try to explain this as clearly as I can:\n\nI am dealing with data for which I need to calculate inter-rater reliability. Here's the scenario: Two people code 20 videos using 3 variables -- X, Y, and Z. X means low quality, Y means moderate quality, Z means high quality. We are looking at percentage of time each variable was coded. \n\nFor example, Person 1 codes 5-minute video. 1 minute of it is coded as X, 2 minutes coded as Y, and 2 minutes coded as Z. That means 20 percent is coded as X, 40 percent is coded as Y, and 40 percent is coded as Z. \n\nPerson 2 codes the same video: 25 percent coded as X, 35 percent coded as Y, and 40 percent coded as Z. \n\nNow, here's what I'm wondering about: Can I create a composite score here? If we multiply %X by 1, %Y by 3, and %Z by 5, then every video is given an overall score ranging from 100 to 500. Person 1's video would have a composite score of 20+120+200= **340**. Person 2's video would have a composite score of 25+105+200= **330**. \n\nRepeat this process for all 20 videos, and run an intraclass correlation to assess the inter-rater reliability between the two coders. Hope that makes sense. Thanks a lot.\n\n",
        "created_utc": 1523130589,
        "upvote_ratio": ""
    },
    {
        "title": "What are the most visited places on the monopoly map?",
        "author": "Gaponya",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8akftw/what_are_the_most_visited_places_on_the_monopoly/",
        "text": "So i know what to buy and what not next tims.",
        "created_utc": 1523129463,
        "upvote_ratio": ""
    },
    {
        "title": "Can someone explain the intuition behind hypothesis testing, confidence interval and p-values.",
        "author": "Wickedmittal",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aj8lu/can_someone_explain_the_intuition_behind/",
        "text": "I don't understand on what basis do we say that reject the hypothesis if critical value is beyond significant value(where does it even come from) and accept it when it's not.\nAlso when testing p value, we reject if values more extreme than p value are less likely to be found that our significance. I understand the reasoning behind p-values, that if h0 were true, than the sample mean should be very likely to be found and vice versa  if it were false. But then why do we look for all the value extreme than p-value.?",
        "created_utc": 1523119085,
        "upvote_ratio": ""
    },
    {
        "title": "Are there any sites like Paul's Online Math Notes for stats?",
        "author": "linyeah",
        "url": "https://www.reddit.com/r/AskStatistics/comments/2mydu7/are_there_any_sites_like_pauls_online_math_notes/",
        "text": "",
        "created_utc": 1523117053,
        "upvote_ratio": ""
    },
    {
        "title": "Understanding changes in Pearson-r",
        "author": "CoryRauch",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aiuwn/understanding_changes_in_pearsonr/",
        "text": "General idea is that participants responded to a survey in which they self-reported the importance of 5 metrics. Following this they each responded to scenarios which reflected these same metrics in two different conditions. Pearson-r was calculated to compare the correlations between the avg self-reported importance of each metric and the avg score of each metric in the two conditions.\n\nFrom condition A (standard) to B (manipulation) r dropped for one of the metrics .06. However, r increased .07, .16, .04, .17. \n\nSample size is only 46 though. \nI guess my question initially is can differences in correlations be a meaningful finding in any circumstance? I was only able to speak very briefly with my advisor before the weekend but he didn't seem particularly interested and mentioned running a factorial ANCOVA on Monday. \n\n\ntldr: Can differences in correlations be a meaningful finding in any circumstance? ",
        "created_utc": 1523115764,
        "upvote_ratio": ""
    },
    {
        "title": "Can I use the principles of the Central Limit theorem when conducting hypothesis tests?",
        "author": "Bish-Bash",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8airyg/can_i_use_the_principles_of_the_central_limit/",
        "text": "I have some highly skewed sample data of size 5000. I need to work out a 95% confidence interval for these data. Is it valid to create a sampling distribution of means that resembles a normal distribution and then work out the confidence interval? Will my result still be statistically significant with regards to the raw data?\n\nI also have to conduct a two sample t-test on the means of two similar variables. Again, both variables are not normally distributed but t-tests assume a normal distribution. Is it valid to replicate a normal distribution with both variables with a sampling distribution of means, before I take the test? ",
        "created_utc": 1523115037,
        "upvote_ratio": ""
    },
    {
        "title": "How to write this equations?",
        "author": "irishrapist",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aiks4/how_to_write_this_equations/",
        "text": "Using logistic regression, dependent variable is CEO turnover, independent variables are ROA, TOBINS'Q, EPS and LONGTERMDEBT. I'm using lagged values - so the independent variables from the 2009 to predict the CEO turnover in 2010 and using fixed effects to account for differences between industries. \n\nIn STATA the command I used was \"logit turnover l1ROA, l1TOBINS'Q, l1EPS, l1LONGTERMDEBT, i.NACE\"\n\n(nace is the code for each industry)\n\nI'm a bit of a noob, so please bare with me. I wrote \n\n\"P (CEO turnover) = 1 /(1+ e^ -(β1+β2x2i +···+βkxki +ui )) \"\n\nIn this equations how do I explain the model I used?\n\nSomething like this: The model used is a linear model: Log(Pi/(1-pi) = beta1 + beta2*X2i + …\n\nand this\n\nYit = const + beta1*ROAt + beta2*Tobins’ Q + beta3*EPS + beta4*LONGTERMDEBT\n\nAdditional questions:\n - How do I put the fixed effects for industry in there?\n\n - To account for the lagged values is putting \"beta1*ROAt-1\" enough?\n\n - Do I write \"const\" or something else that means that?\n\n - How should the rest of the equations go?\n\n - Anything I could read to better understand how to write this equations?",
        "created_utc": 1523113219,
        "upvote_ratio": ""
    },
    {
        "title": "Recruiting statisticians/data analysts participants for a research study on career success",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ahxq6/recruiting_statisticiansdata_analysts/",
        "text": "[deleted]",
        "created_utc": 1523106588,
        "upvote_ratio": ""
    },
    {
        "title": "Quantify associations between variables.",
        "author": "antespo",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8agzq6/quantify_associations_between_variables/",
        "text": "I have have a data set where I am trying to find if there is any correlation between variables.\nMy data set looks something think this:\n\nCompany | Temp | Days in use | Type of Failure\n--------|------|-------------|----------------\nA       | 80   | 756         | Fracture\nB       | 60   | 350         | Corrosion\nC       | 95   | 164         | Corrosion\nB       | 82   | 547         | Impact\n\nHow would I got about finding correlations between `Type of Failure` and the other variables? For `Company` I grouped them together and counted each `Type of Failure` and made a simple bar graph showing each company with their total for each `Type of Failure`. Is there a better way to show this than making just a bar graph? And how would I go about proving or disproving correlation for the integer variables? i.e. is `Days in use` linked to a `Type of Failure`. ",
        "created_utc": 1523092926,
        "upvote_ratio": ""
    },
    {
        "title": "Question about interpreting significance between groups while compared to chance performance",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8af8bf/question_about_interpreting_significance_between/",
        "text": "[deleted]",
        "created_utc": 1523069068,
        "upvote_ratio": ""
    },
    {
        "title": "Statisic analysis for two or more dose-response curves?",
        "author": "themazerunner26",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aetmi/statisic_analysis_for_two_or_more_doseresponse/",
        "text": "Hi. What statistic is best to use when comparing dose-response curves? A dose response curve typically looks like [this ](http://anesthesiology.pubs.asahq.org/data/Journals/JASA/931097/30FF2.png). A curve represents a set of known concentrations plotted against the response. How do you propose to compare the effect of two curves? Or even multiple curves?",
        "created_utc": 1523064780,
        "upvote_ratio": ""
    },
    {
        "title": "Is there a way to calculate the standard deviation of individuals from the standard deviation of multiples?",
        "author": "PhillyFrank76",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8adqky/is_there_a_way_to_calculate_the_standard/",
        "text": "I work in the Pharmaceutical industry and during development a common test we use measures the concentration of 10 tablets all dissolved at one time (that is, we get the average concentration of the 10 tablets, but don't know the concentration of each individual tablet).    If we know the standard deviation of these \"average of 10 tablet\" concentrations, is there a way to calculate the standard deviation of the individual tablets (assuming everything is normal, of course)?    I had a mistaken understanding of Standard Error of the Mean that made me think that the standard deviation of individuals would just be the square root of 10 times the standard deviation of the \"averages of 10,\" but that does not seem to be right. \n\nOriginal post edited to include the example below for clarity:\n\nExample: 1) We make a batch containing a total of 1,000,000 tablets. 2) A chemist takes 10 of those tablets, and does a chemical assay (\"dissolve them in a solvent and perform an HPLC analysis\" if you want the technical term or \"does Chemistry stuff and gives us a number that tells us the average concentration of those 10 tablets\" if you don't.). \n3) The chemist repeats step 2, twenty times, so we have 20 numbers. Each of those is the average concentration of 10 tablets.\n4) I can calculate the mean and standard deviation of the 20 measurements of 10 tablet-averages.\nMy question is, do I have enough information to estimate the standard deviation of all 1,000,000 tablets in the batch? \n\nI didn't know what to Google to try to find this answer.  Any help would be appreciated!\n",
        "created_utc": 1523054148,
        "upvote_ratio": ""
    },
    {
        "title": "Could you explain how to distinguish between modifiers and confounders?",
        "author": "yinyang_zen",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8adpyb/could_you_explain_how_to_distinguish_between/",
        "text": "I had a professor tell me that every confounder is a potential modifier. Could you throw some light on this or suggest some reading material?",
        "created_utc": 1523054014,
        "upvote_ratio": ""
    },
    {
        "title": "Is who is right in this reddit debate? Is the correlation in a least squares regression the same as its effect size?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/dataisbeautiful/comments/8aajfb/teacher_evaluationstudent_grade_correlation_oc/dwxhfni/?context=10000",
        "text": "[deleted]",
        "created_utc": 1523051238,
        "upvote_ratio": ""
    },
    {
        "title": "Statistical test for RCB ANOVA...or maybe ANCOVA...or maybe nested (?)",
        "author": "Takeurvitamins",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8acqek/statistical_test_for_rcb_anovaor_maybe_ancovaor/",
        "text": "Hi all.\n\nI designed my experiment in a way that I think presents me with a few choices for analysis.\n\nThe experiment was like this:\n\nI work with 2 mussel species (Z and Q).\n\nI put 4 of each species in a pipe in the river (each of the four got their own little chamber inside).\n\nEach pipe had a baffle on the front and back to change water flow into and out of the pipe\n\nI made four baffle types (A, B, C, D), with the intent that each one would allow faster/more water flow than the previous (ie A&lt;B&lt;C&lt;D). \n\nI grouped one of each pipe type together to make a replicate (right?) and attached these replicates to a cinderblock\n\nThere were 10 cinderblocks total\n\nI put these underwater, cleaned them every two weeks, and took pre- and post- measurements of mussel body size, and also got attachment strength.\n\nSo I could just analyze the data as a a 4x2 ANOVA, with the pipe type (A, B, C, D) vs. species (Z vs Q) with something like body length as the response variable.\n\n\nBUT! in each pipe, I also included a hard plaster block that dissolved over time under water, ostensibly with higher dissolution due to increased water flow. I checked to see if the pipe baffle had any affect with a one way ANOVA (response variable = amount dissolved; four pipe types) and I found that the baffles basically did what I wanted them to (A&lt;B&lt;C&lt;D), but not as strongly as I had hoped (Only pipes A and D are significantly different).\n\nSo I could do an ANCOVA using these plaster blocks, with species as the factor, plaster mass lost as the covariate, and body length as the response variable.\n\nMy questions are: \n\n1) how do I tell if I should go with the ANOVA or ANCOVA?\n\n2) Can/should I make this nested by putting plaster mass lost nested in pipe?\n\n3) the blocks are random effects because I wasn't focused on their impacts, do I make them interact with every factor or just include it as it's own random factor?\n\nI'm using JMP for the analysis. Any help would be appreciated.\n\n",
        "created_utc": 1523045842,
        "upvote_ratio": ""
    },
    {
        "title": "Predicting customer ordering activity using stats",
        "author": "ProtContQB1",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8acmn5/predicting_customer_ordering_activity_using_stats/",
        "text": "Hi all,\n\nThe business I work for has a very (very) short-term production model and we're constantly running into problems with timing of production and ordering from our vendors based on the timeframe that we have to allow for our customers to order. Our products are very perishable, so stocking up also doesn't work because we also easily run into the risk of having to disposed of product because its no longer usable.\n\nAs an example, we have to have our orders for Product X, Y, and Z delivered to our vendor by 5:05pm, however, we have important customers who are occasionally late with their orders and they get placed after 5:05pm after the cut-off and we have to go into a mad scramble when that happens to try and fulfill the order.\n\nUnfortunately, contacting customers when they're late with their orders has proven to not be working out, so I've been instructed to try and predict ordering activity for the day so we can begin the process of placing orders in advance in an effort to predict customer needs.\n\nI can produce reports that can be easily copied to excel that show a history of ordering activity for each product (with the date), however, I haven't done statistics since college and I'm way outside of my field of expertise.\n\nI've spent quite some time on google reading about how to do forecasts by using statistical analysis, but the field of doing this kind of forecasting is so broad that I'm feeling a bit overwhelmed. I feel like I'm going to keep reading and picking out bits and pieces that apply to me, and trying to put something together.\n\nMy initial thought is that I should at least be able to do some kind of predictive analysis by finding means and standard deviations, but that's really all I'm capable of.\n\nBecause of the constraints that I'm under and because this type of forecasting and prediction is going to be more essential as the business grows, I'd really like to learn as much as I can in order to be more useful. I understand it can very complicated, but I'd like to start from somewhere.\n\nThank you!",
        "created_utc": 1523045029,
        "upvote_ratio": ""
    },
    {
        "title": "Non-statistician looking to improve my approach to a dataset.",
        "author": "Pleonastic",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8abxu0/nonstatistician_looking_to_improve_my_approach_to/",
        "text": "Hi, statisticians!\n\nI have not posted here before, but I'll try my best to adhere to the rules. \n\nI have a dataset consisting of 3 categories spanning 12 months. I need to choose some of the months in order to do qualitative analysis, because I can't/don't have time to choose all 12. \n\nWhat I've done, as an absolute amateur, is to calculate the average numbers of the 3 categories and chosen the mean result.\n\nThe issue is, I know my analysis is going to cause quite a bit of ruckus. There are, in particular, two opposing groups that my analysis applies to, and both of them could, in a sense, be considered non-violent extremists.\n\nSo in order to avoid as much trouble as possible, I'd very much appreciate any advice on which model I should use - after reading the provided link in the sidebar, I didn't understand everything, but I certainly didn't understand what would be the most justifyable when used to select data for qualitative analysis.\n\nHelp or no help, thanks for reading!\n\nEdit: it's going to have to be ordinal.",
        "created_utc": 1523039643,
        "upvote_ratio": ""
    },
    {
        "title": "Statistical test for comparing racial demographic data across 3 counties?",
        "author": "throwback0415",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8abx24/statistical_test_for_comparing_racial_demographic/",
        "text": "Hello, I read the \"choosing the correct test\" page on the sidebar, but I'm still unsure of which test to use. First time posting on reddit, so hope I'm not breaking any rules!\n\nI have demographic data for 3 different counties (so each county has X% white, Y%black, etc. all total, there are 9 racial groups) across multiple years . I want to see if racial composition (measured in percentages) is significantly different among those 3 counties over time. Which test should I use?\n\nTo clarify, more my data is basically like this (not exact numbers):\n\nCounty X:\n2010: 50% White, 20% Black, etc.\n2009: 48% White, 19% Black, etc.\n2008: ...\n\nCounty Y: \n2010: 45% White, 20% Black, etc.\n2009: 50% White, 25% Black, etc.\n2008: ...\n\nAnd a county z.\n\nI basically want to see if the changes across time are significantly different among the three counties. (Basically, testing to see if the change from 2009 to 2010 in County X is significantly different from that same change in county Y).",
        "created_utc": 1523039491,
        "upvote_ratio": ""
    },
    {
        "title": "Confused on interaction term multiple regression",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8abrws/confused_on_interaction_term_multiple_regression/",
        "text": "[deleted]",
        "created_utc": 1523038386,
        "upvote_ratio": ""
    },
    {
        "title": "Quantile regression - Treatment effects on income",
        "author": "Foremanator",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8ab8mb/quantile_regression_treatment_effects_on_income/",
        "text": "I am looking at the distribution of effects and want to know whether the poorest or richest members of society benefit the most, in terms of income, from an intervention.  \n\nI am using stata and am struggling to identify what my dependent variable should be based on the fact I want to analyse the differentiated income groups. \n\nI want to use quantile regression to explore the heterogeneous effects of a micro entrepreneurship programme on income. I am using an existing data set and want to see if the effect of the programme differs across the distribution of the sample. \n\nShould I use an interaction term of change in income over the time period as my dependent variable? Or will the end survey income be sufficient to demonstrate how quantiles benefited less/more (whilst controlling for other covariates, including income at the baseline)?",
        "created_utc": 1523034382,
        "upvote_ratio": ""
    },
    {
        "title": "Non-parametric test for multiple comparisons with 3 interacting factors?",
        "author": "terrenity",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8aafs5/nonparametric_test_for_multiple_comparisons_with/",
        "text": "Hi all,\n\nI have a data set with three factors: position (two levels: 'a' and 'b'), timepoint (three levels: 7, 9 ,14) and treatment (four levels: 'red', 'orange', 'yellow', and 'control'). My response variable is continuous and ranges from 0.001 to 3.800. The response variable does not change linearly across timepoints, even within treatment-position combinations, so I have been considering it as a factor rather than an integer. There are highly significant two- and three-way interactions between my factors. I have analyzed similar data sets in the past with a mixed linear model, but I am unable to coerce this data set to a normal distribution (the best I've gotten is with a square root transformation, but the residuals are still significantly non-normal). \n\nI am interested in the individual effects of the 'red' 'orange' 'yellow' treatments compared to the 'control' treatment, at the different sample positions. For example, I would like to be able to say \"the yellow treatment increased the response variable relative to the control treatment at the first two timepoints at sample position A, but had no significant effect at position B\".  The response variable does not change linearly across timepoints, even within treatment-position combinations. \n\nDoes anyone know of a statistical test I can use? Or is there a chance I can use a mixed linear model even though I'm violating the normality assumption? I'm way out of my comfort zone here. I am using R for all my data analysis.\n\n[Here is a boxplot](https://imgur.com/qAXLnl0) of my untransformed data for reference. And [here's a qqplot](https://imgur.com/LKWpkUa) of the residuals for the best transformation/linear model I've been able to fit.\n\nThank you!!",
        "created_utc": 1523028597,
        "upvote_ratio": ""
    },
    {
        "title": "What is considered standard practice for displaying tables that contain a lot of zeros?",
        "author": "Kimi_Hill",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a92ti/what_is_considered_standard_practice_for/",
        "text": "I am creating a website that displays statistics of Formula 1. \n\nCurrently, I have a lot of tables that have zero for certain stats - what is the best menthod to display these? Is a blank cell appropirate, perhaps a '-' or is it better to display a 0 despite this leading to a lot of 0s meaning the non-zero numbers don't stand out as much?",
        "created_utc": 1523017621,
        "upvote_ratio": ""
    },
    {
        "title": "By using the Rsquare value, can I work out the percentage impact it has on another variable?",
        "author": "Bananaface21",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a8fnb/by_using_the_rsquare_value_can_i_work_out_the/",
        "text": "I have 6 variables and they all have an impact on the death rate of bees. Could I use the Rsquare value from each individual regression between deaths and then one of the variables to work out the percentage impact the variable has on deaths? \nFor example, say the R2 values are 0.18, 0.51, 0.002, 0.1 and 0.3. I then add them together leading to having the number 1.092. Then I go (0.18/1.092)*100  and then that  would get a % of 16.48% \nIs this legitimate way of going about things or have I done some fake maths? Thank you ? \n\nBasically what I'm trying to do is work out what percentage of deaths each variable is able to be associated with.",
        "created_utc": 1523010682,
        "upvote_ratio": ""
    },
    {
        "title": "Can anyone please help me with mean-centering interaction terms?",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a79r2/can_anyone_please_help_me_with_meancentering/",
        "text": "[deleted]",
        "created_utc": 1522995439,
        "upvote_ratio": ""
    },
    {
        "title": "Need help getting the concept of mean-centering",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a6gzf/need_help_getting_the_concept_of_meancentering/",
        "text": "[deleted]",
        "created_utc": 1522986754,
        "upvote_ratio": ""
    },
    {
        "title": "How to find the ARMA model that best fits my data in R?",
        "author": "zzzzz94",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a6f0u/how_to_find_the_arma_model_that_best_fits_my_data/",
        "text": "So I have a docomposed data set and want to fit the \"random component\"\n\nsay the data is ts.decomp\n\nHow do I do this? What commands should I use?\n\nThanks\n",
        "created_utc": 1522986228,
        "upvote_ratio": ""
    },
    {
        "title": "ARIMA(1,1,1) model - seems too accurate.",
        "author": "Altarosk",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a5xyt/arima111_model_seems_too_accurate/",
        "text": "Hello everyone, for one of my classes, I had to make a forecast for a given currency, mine was Gold. I wanted to do a linear regression using expected inflations and volatility and their interaction, however, I realized there was very strong positive autocorrelation (DW test &lt;0.1 and ACF basically just a right angle triangle). I used Minitab btw.\n\nAnyway, because of that I thought a time series model would be better to take that into account that and avoid type 1 error. Here is what I did:\n\nGot monthly gold data from 2003.\nnon - stationary so I differentiated once and looked at both ACFs and PACFs to conclude the appropriate models. Also saw some spikes every 5 months so I added a seasonal AR and MA, but the improvements were so marginal that I just discarded them.\nthe ARIMAs had VERY low MAD, MSE and MAPE score (the MAPE score is around 3% for example)\neach variable is VERY significant.\nAnd that's my problem, it seems too good. Here is a picture of my ARIMA(1,1,1)(0,0,1)5: https://imgur.com/a/qqpc7\n\nThe other models I've made, including the ARIMA(1,1,1) of the title are almost identical, which makes sense since I didn't differentiate the seasonal which makes it kinda pointless right?\n\nI'm not really good at stats, tbh, so I don't trust myself. Is this accurate? A reliable model to estimate short-term gold prices? What could I have done wrong? The paper is already given in, so this is just out of pure curiosity. I also wanted to expand this model into an ARIMAX, but I need to learn some R before.\n\nAlso, as I said, I'm quite amateur so I might not understand some of the terms you use.\n\nThank you very much!",
        "created_utc": 1522981840,
        "upvote_ratio": ""
    },
    {
        "title": "Random match probability and \"A second hit\"",
        "author": "dfoley323",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a5jqz/random_match_probability_and_a_second_hit/",
        "text": "I am reading a genetics book about statistics and it is talking about Random Match Probability.  It is talking about how if the RMP stat is 1 in a million, then the odds of picking a random person and their profile matching is 1 in a million.  Where i get lost is the next line:\n\n\"Consider a population comprising one million + 1 individuals, where the additional “+1” is the offender and there are one million innocent people. Then it can be calculated . . . that the probability of at least one match with the offender amongst the one million innocent people is just over 3 out of 5 (0.63). \"\n\nSo i get it, in 1,000,001 people, you have 2 people with the profile, 1 is the suspect, and the other is a random person, but where do the odds of 3/5 come from. ",
        "created_utc": 1522978422,
        "upvote_ratio": ""
    },
    {
        "title": "What is your favorite software for flashy/sexy visualizations?",
        "author": "Jolator",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a459b/what_is_your_favorite_software_for_flashysexy/",
        "text": "I work for a small company that is adding a laboratory, and my boss wants data management software that will kick out really slick looking visualizations. He's willing to buy something expensive as long as we can wow our customers. He might go up to $3500 if the software's website is colorful enough.\n\nPersonally I care most about what will give us the most convenient batch/data entry, easy to use report creation based on whichever kind of testing we're doing, statistical analysis, etc. But I'm the one who's going to use it, at least for now.\n\nI'd love to know if you have any favorite or wish-list software that would make us both happy!\n\nEdit: I also wonder if the solution might be using dedicated software to manage samples/testing, and export to something like Tableau for the flashy stuff. ",
        "created_utc": 1522966860,
        "upvote_ratio": ""
    },
    {
        "title": "Stats Project",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a27c3/stats_project/",
        "text": "[deleted]",
        "created_utc": 1522952878,
        "upvote_ratio": ""
    },
    {
        "title": "Estimate the data generating distribution with non-i.i.d data",
        "author": "Secret_Identity_",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a22xw/estimate_the_data_generating_distribution_with/",
        "text": "I am looking at bid amounts for cars sold at a sealed auction (only the seller has all the information). I am trying to predict the number and magnitude of offers that a car will receive. Some of the cars only have one bid, but other cars are very popular and have dozens of different offers. Since the data is not i.i.d, I am not sure of the best way of moving forward. As an interim solution I have focused on the sales price, but it feels like I am throwing out a lot of useful information.\n\nAre their established practices for using all the data? This seems like a something that might come up in physical sciences (multiple observations of some subjects, but not others).",
        "created_utc": 1522952031,
        "upvote_ratio": ""
    },
    {
        "title": "Calculating Population Standard Deviation with Population Subset Standard Deviations",
        "author": "thankkieu",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a1z6r/calculating_population_standard_deviation_with/",
        "text": "I'm working with aggregated data and I am trying to use the subset standard deviations to back into the population standard deviation. I'm testing different methods to see what works.\n\nIf I know that these Groups are independent (do not intersect) and their union is the population then I'm looking for a way to get the population standard deviation.\n\nThis is the aggregated data set I'm testing with. I happen to know the population standard deviation in this case and it's 3.6243560125013365. So I'm looking for a method that uses the figures below to arrive to the 3.62435 figure.\n\nGroup / Std Deviation / Group Size\n\nA\t2.598148\t227741\n\nB\t1.966262\t13284\n\nC\t5.360645\t71247\n\nD\t5.508427\t6605",
        "created_utc": 1522951330,
        "upvote_ratio": ""
    },
    {
        "title": "Is there an equation for this?",
        "author": "Nephisimian",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a1d45/is_there_an_equation_for_this/",
        "text": "I'm going to use a random number generator to generate an integer between 1 and 100 to generate the number Y. If Y is equal to or lower than set value X, then I'm going to roll a second number, Z. If Z is equal to or less than Y, then I succeed. I've become stumped on figuring out what the chance of succeeding is, but there's a maths for everything so is there a maths for this?\n\n",
        "created_utc": 1522947139,
        "upvote_ratio": ""
    },
    {
        "title": "Unsure how to create a meaningful representation/interpretation from my generated data.",
        "author": "Shmink_",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a15es/unsure_how_to_create_a_meaningful/",
        "text": "Apologies for the obscure title, I'm far from a statistician. I was wondering with the following data below is there anyway of drawing any conclusions? Generating any kind of graphs? or anything that would help present or interpret the following data rather than just pasting it. I suppose this question is too vague that it may be downvoted to oblivion but statistics is not my field.\n\n[CSV file. 100,000 rows.](https://www.dropbox.com/s/yv1wtzwsi8kjk19/100ksamples.csv?dl=0)\n\n\nDue to my limited knowledge in statistics, I'm not sure what kind of statistics could even be applied. There are 2 columns, 'Seed' and 'Time'. The seed value contains hexadecimal values. I'm currently converting them all to decimal values to see if there is any kind of correlation between time and the decimal value. Would it be possible to say do it in such a way that common 'Seeds' could be looked at and notice the average time for those seeds? Or perhaps a better method? To me it seems like random data that you can't really do much about but as I said I'm no expert. Again it is a bit of an open question so anything I haven't mentioned that you deem relevant just ask. ",
        "created_utc": 1522945617,
        "upvote_ratio": ""
    },
    {
        "title": "Uneven sample size in paired samples t-test",
        "author": "sandraostero",
        "url": "https://www.reddit.com/r/AskStatistics/comments/8a05g5/uneven_sample_size_in_paired_samples_ttest/",
        "text": "Hi\n\nSo I did an experiment for my masters' thesis, where I did a stress-test of some fish, where I measured cortisol (stress-hormone) over time. I have a suspicion that there is a difference in cortisol concentration between male and female fish. So I want to test this hypothesis using a paired-samples t-test. \n\nI did the test using the average concentration for each gender (6 time-steps, so 6 values for each gender). I get that there is no significant difference between the genders.\n\nMy question is now: is it enough just to use the average concentration for the test? my problem is that there is an uneven distribution of males and females on each time-step, and using the average does not take this into account.\n\nAnd if I use all the values, how do I do it?\n\nI did the other test in R, making two vectors for the genders, then using the t.test with paired=TRUE. If the vectors are not the same length, they can't be paired. Can you pair groups of values instead?",
        "created_utc": 1522938537,
        "upvote_ratio": ""
    },
    {
        "title": "IBM SPSS 24 help required.",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89zv9v/ibm_spss_24_help_required/",
        "text": "[deleted]",
        "created_utc": 1522936406,
        "upvote_ratio": ""
    },
    {
        "title": "Is multiple regression the right choice?",
        "author": "PippoMiller",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89ztl9/is_multiple_regression_the_right_choice/",
        "text": "Hoping to get help selecting the correct test to analyse my data:\nI have two variables (Perceived stress and Physical activity levels) which were recorded each week for a total of 10 weeks. I then have a single measure of academic achievement (i.e. average % score for the semester).\nIm looking for potential relationships between these variables. I was thinking multiple regression but unsure how this is affected by having repeated measures of my two IVs? Any help or advice would be greatly appreciated.",
        "created_utc": 1522936044,
        "upvote_ratio": ""
    },
    {
        "title": "Best way to compare two different demographics using data obtained with a 7-point Likert Scale",
        "author": "dropout32",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89ys7c/best_way_to_compare_two_different_demographics/",
        "text": "This is sort of two questions. \n\n1) Using answers obtained through a 7-point Likert Scale I want to compare two different demographics. \n\nFor example: I have 31 female respondents and 79 male respondents, but I'm unsure of the best way to go about analysing this data, especially with different sized samples. \n\nI want to check for significance, if any, between their responses.\n\n2) Would be comparing 4 different demographics, separated by age, for significance. \n\nI haven't done any statistics or statistical analysis in the past and google is just confusing things more, any ideas? \n",
        "created_utc": 1522926648,
        "upvote_ratio": ""
    },
    {
        "title": "Where can I find a step-by-step lesson/lecture on manually calculating Cronbach's alpha?",
        "author": "AncientCaptcha",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89yigx/where_can_i_find_a_stepbystep_lessonlecture_on/",
        "text": "",
        "created_utc": 1522923419,
        "upvote_ratio": ""
    },
    {
        "title": "Doubt concerning Experiment vs Observational Study",
        "author": "ccaaccaahhuueettee",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89y7jc/doubt_concerning_experiment_vs_observational_study/",
        "text": "On Khan Academy I am completing a test about Study Design and I have doubts between the differences between experiment and observational study in the following context.\n\n&gt; Giovanna has two possible driving routes to her new workplace, and she is having a hard time figuring out which is faster. The first route is shorter, but usually has more traffic than the second route.\n&gt; She decided to conduct a small study. Over a period of 5 weeks, she used the first route in the first half of the week (Monday, Tuesday, and Wednesday), and the second route in the second half of the week (Thursday and Friday). Each day she recorded how long it took her to get to work, and by the end of the 5 weeks she calculated the average driving duration for each route.\n\n&gt; What type of statistical study did Giovanna use?\n&gt; \n&gt; * Sample study\n&gt; * Experiment\n&gt; * Observational study\n\n&gt; Is the study appropriate for the statistical questions it's supposed to answer?\n&gt; Mark the most suitable choice.\n&gt; \n&gt; * Yes, because it allows to compare between the driving durations in the two routes.\n&gt; * No, because there was no randomization.\n&gt; * No, because she didn’t compare the two routes with a third, neutral route.\n&gt; * No, because she should’ve asked someone else to drive.\n\nNow, I understood this to be an observational study, because she observes and doesn't assign treatments. Whereas in an experiment she would have applied a treatment to an experimental unit.\nAs for the second question: I feel, yes, it was appropriate, but perhaps she should still have randomised the days.\n\nKhan Academy gives the following as the correct answers:\n\n* Experiment\n\n&gt; In an experiment, one parameter of the population is actively changed to see the effect on the other parameter. In this case, the driving route was actively assigned by Giovanna to each work day to assess its effect on the driving duration. Therefore, this is indeed an experiment.\n\n* No, because there was no randomization.\n\n&gt; Randomization is important to smooth out any factor other than the driving route that could affect the driving duration. If Giovanna always took the first route on Monday, Tuesday, and Wednesday, and the second route always on Thursday and Friday, any difference in driving duration couldn't be attributed to the route alone. Maybe traffic on Monday is exceptionally bad? Maybe some roads are closed on Friday, which disrupts traffic around town?\n\nCan somebody give me an insight as to why this is an experiment and not an observational study? Is it because there were two control groups with differing sets of instructions, yet they were all performed by the same person on different days?",
        "created_utc": 1522919562,
        "upvote_ratio": ""
    },
    {
        "title": "Experiment to see if a person can differentiate between two flavours of marshmallows, while blindfolded",
        "author": "shanef1978",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89xvbk/experiment_to_see_if_a_person_can_differentiate/",
        "text": "A work colleague said she could differentiate between white and pink marshmallows (not sure what the flavours are) while blindfolded.  Since we were at work, and we didn't have enough time to do it properly, I gave her five white marshmallows with her eyes closed.  She got two correct. \n\nI was thinking how I might do this properly.  It's been years since I did a university course on experimental design.  Any ideas? ",
        "created_utc": 1522914945,
        "upvote_ratio": ""
    },
    {
        "title": "Treatment effect after time",
        "author": "Sheler",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89xcur/treatment_effect_after_time/",
        "text": "Hey,  \nI have some big pile of data I need to analyze and I got stuck somehow. I would really appreciate any input!  \nThe Q is here on [stats.stackexchange.com](https://stats.stackexchange.com/questions/338650/treatment-effect-in-time)  \nI think it's rather interesting problem.  \nThank you!!",
        "created_utc": 1522908630,
        "upvote_ratio": ""
    },
    {
        "title": "Unequal group sizes",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89w2hx/unequal_group_sizes/",
        "text": "[deleted]",
        "created_utc": 1522895789,
        "upvote_ratio": ""
    },
    {
        "title": "Need help with mean-centering with interaction term",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89v8ks/need_help_with_meancentering_with_interaction_term/",
        "text": "[deleted]",
        "created_utc": 1522888766,
        "upvote_ratio": ""
    },
    {
        "title": "What type of stat test should I use.",
        "author": "CaptainNinjaKid",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89v0c9/what_type_of_stat_test_should_i_use/",
        "text": "Did a grade 11 biology lab, requires stat test, don't know what each do. The lab was testing if there was a significant difference between population growth of Lemna (type of aquatic plant) and 5 different colors of light.",
        "created_utc": 1522886921,
        "upvote_ratio": ""
    },
    {
        "title": "Comparing before and after test results, t or anova?",
        "author": "IsWhatItIsWhichIs",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89uzft/comparing_before_and_after_test_results_t_or_anova/",
        "text": "I've made a learning app for an undergrad project. I've got a study where there's 2 groups of students.\n\nGroup A does test 1 -&gt; textbook revision -&gt; test 2\n\nGroup B does test 1 -&gt; learning app -&gt; test 2\n\nI wanna make some conclusions about the effectiveness of my learning app in comparison to textbook revision. I was thinking of doing a t test on the % test differences across the 2 groups (if that's how it works), but I've been receiving mixed messages - I've had some people tell me I need to use some form of ANOVA test. Whatever I do doesn't have to be incredibly thorough/valid, but it also can't be glaringly wrong.\n\nAny guidance would be hugely appreciated!",
        "created_utc": 1522886708,
        "upvote_ratio": ""
    },
    {
        "title": "McNemar, Chi-square, or.. neither?",
        "author": "Jaguarsftw",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89uowu/mcnemar_chisquare_or_neither/",
        "text": "Hi all,\n\nI'm new here and I read the ucla.edu 'What statistical test to use' page, but I'm still confused and was hoping you guys could help me out.\n\nBasically I've run an experiment in which people can choose to accept or reject a gamble. If they accept it, they have a 50% chance of winning (+150 points) and 50% of losing (-100 points). This gamble is repeatedly offered to them, 8 times in a row.\n\nI have 33 treatment subjects and 34 control subjects, and wanted to look at the proportion of gambles accepted (e.g. for treatment subjects, the number of gambles accepted out of 33*8=264 decisions) and compare the proportions for treatment vs control subjects. I also wanted to compare the proportion of gambles accepted by males vs females. Am I correct in understanding that I should be using the Chi-squared test for equality of proportions in these cases?\n\nThe second problem I have is that I would like to compare the % of gambles accepted after winning the previous gamble, versus after losing the previous gamble. Since subjects could have, across the 8 time periods, both won and lost some of their gambles, they can fall into both categories. So I suspect the two samples (those deciding after winning previous gamble vs those deciding after losing previous gambles) are not independent and a chi-squared test is not suitable. I thought McNemar's test sounded like what I needed, but the number of people deciding whether to accept or reject a gamble after winning the previous gamble, is different than the number of people making a decision after losing the previous gamble, so I don't really understand how they would be paired either.\n\nSorry if these are really basic questions but I'm really stumped and would appreciate any help I could get.\n\n",
        "created_utc": 1522884379,
        "upvote_ratio": ""
    },
    {
        "title": "ANOVA , variance estimate, there seems to be two ways",
        "author": "linyeah",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89uneu/anova_variance_estimate_there_seems_to_be_two_ways/",
        "text": "\n\n\n\n\n\n\n\n\nIt seems that I can calculate the variance, s^2, two ways\n\n1 : using \n\n    s^2/n = variance of the sample means\n\nthen\n\n    s^2 = variance of the sample means * n\n\n2 : using \n\n    s^2 = (SS errors) / (degrees of freedom)\n\n********************\n\nBut sometimes I'm asked to give **the** estimate of the variance, and when I am\nthe answer corresponds to the version found by method 2 above.\n\nI'm not sure why this is though. I can use that approach instead, I just don't\nreally get why it would be invalid to use method one above\n\nthanks\n",
        "created_utc": 1522884047,
        "upvote_ratio": ""
    },
    {
        "title": "A few questions about mean-centering",
        "author": "[deleted]",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89ud6r/a_few_questions_about_meancentering/",
        "text": "[deleted]",
        "created_utc": 1522881847,
        "upvote_ratio": ""
    },
    {
        "title": "What statistical analysis?",
        "author": "MadroxKran",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89tlbk/what_statistical_analysis/",
        "text": "I did check the link in the FAQ, but it's a bunch of gobbledygook to me.  I am not a statistician of any sort and have never run a real analysis.  The book I've got for this research class is worthless, too.  \n\nI'm trying to compare data on the homeless population of some states and cities from before and after implementation of a rapid re-housing program.  It seems pretty straight forward.  I'm going to look at the amount of homeless (by total amount and % of population) and see if it changed.  The hypothesis is that these programs prevent an increase in the homeless population in that area.\n\nIs there any statistical analysis that I should run for this?  I can see making a table with these before and after amounts and percentages and then checking the mean, to show that the programs work or don't on average, but that's all I got.  Is there something to show that these programs are probably the thing that is preventing the increase (if that's what I find)?  Like the amount of people that used the program that year vs. the amount of homeless total?  I don't know if that would be something or what analysis method that would be if it is one.\n\nPlease ELI5 it for me.  \"I think you should use this and measure this against this\" or something like that.",
        "created_utc": 1522876565,
        "upvote_ratio": ""
    },
    {
        "title": "OLS and goodness of fit",
        "author": "GimmeThoseCaps",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89tbsg/ols_and_goodness_of_fit/",
        "text": "I'm trying to figure out which are the best indicators to assess the fitness of my model. Can someone give me an overview about them? Just a simple explanation to make it easier for me to research.\n\n\nWhich indicator/indicators are more important or useful? How do I know the \"confidence level\" of my model - is Rsquare the best measure?\n\n\n",
        "created_utc": 1522874784,
        "upvote_ratio": ""
    },
    {
        "title": "How would a satistical \"thinking machine\" speak?",
        "author": "Life_after_moon",
        "url": "https://www.reddit.com/r/AskStatistics/comments/89t9ug/how_would_a_satistical_thinking_machine_speak/",
        "text": "Hi all and thank you.\n\nI am writing a novel about a sentient computer built on a Bayesian learning network and somesort of \"hypothesis generation\".\n\nIf taken seriously, what would the possible range of such a machine be, assuming the algorithm is trying to \"trick a person into thinking the machine is really a human\".\n\nMy thinking it is of course limited to previous data, sonit would take all it's available \"conversational data\" and run Bayesian stats on it plus given the given \"current\" situational data, and each reply would be like a list of the results with a greater than 99% chance of being the \"correct\" next thing to say to get to it's end goal.",
        "created_utc": 1522874457,
        "upvote_ratio": ""
    }
]